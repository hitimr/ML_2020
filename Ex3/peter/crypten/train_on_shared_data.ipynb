{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's put it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, good! You have: (3, 7, 9)\n"
     ]
    }
   ],
   "source": [
    "#%%writefile train_model.py\n",
    "\"\"\"train_model.py\n",
    "\n",
    "I'm testing if I can sensibly condense a jupyter notebook into a script via %%writefile cell magic.\n",
    "\"\"\"\n",
    "# Load parent folders into path\n",
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "# Import some config variables\n",
    "from config import PETER_ROOT, DATA_DIR, MNIST_SIZE\n",
    "\n",
    "\n",
    "# Plotting\n",
    "from plot_mnist import plot_batch, plot_digit\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import crypten\n",
    "import crypten.communicator as mpc_comm # the communicator is similar to the MPI communicator for example\n",
    "from crypten import mpc\n",
    "\n",
    "assert sys.version_info[0] == 3 and sys.version_info[1] == 7, \"python 3.7 is required!\"\n",
    "\n",
    "print(f\"Okay, good! You have: {sys.version_info[:3]}\")\n",
    "# Now we can init crypten!\n",
    "crypten.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lib/dir_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lib/dir_setup.py\n",
    "\"\"\"dir_setup.py\n",
    "\n",
    "Functions for data directory setup and generation of filename dictionary.\n",
    "\"\"\"\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "def rm_files_in_dir(directoy:pathlib.Path, recursive=False):\n",
    "    if not directory.exists():\n",
    "        print(f\"{directory} does not exist\")\n",
    "    else:\n",
    "        if recursive:\n",
    "            # Simple non-recursive glob --> doesn't look into subdirectories\n",
    "            for file in [x for x in directory.glob(\"*\") if x.is_file()]:\n",
    "                file.unlink()\n",
    "            print(f\"{directory} cleaned!\")\n",
    "        else:\n",
    "            # Use recursive glob\n",
    "            for file in [x for x in directory.rglob(\"*\") if x.is_file()]:\n",
    "                file.unlink()\n",
    "            print(f\"{directory} and it's subdirectories cleaned!\")\n",
    "\n",
    "def check_and_mkdir(directory:pathlib.Path):\n",
    "    if not directory.exists():\n",
    "        print(f\"Directory {directory} created.\")\n",
    "        directory.mkdir()\n",
    "\n",
    "def rm_dir(directory:pathlib.Path):\n",
    "    shutil.rmtree(directory)\n",
    "    \n",
    "def get_filenames(directory:pathlib.Path, participants):\n",
    "    # Specify file locations to save each piece of data\n",
    "    filenames = {\n",
    "        \"features\": directory / \"features.pth\",\n",
    "        \"labels\": directory / \"labels.pth\",\n",
    "        \"b_true\": directory / \"b_true.pth\",\n",
    "        \"test_features\": directory / \"test_features.pth\",\n",
    "        \"targets\": directory / \"targets.pth\",\n",
    "        \"w_true\": directory / \"w_true.pth\",\n",
    "    }\n",
    "\n",
    "    rank = 0\n",
    "    for u in participants:\n",
    "        filenames[\"labels_\"+u] = (directory / (f\"labels_{u}.pth\"), rank)\n",
    "        filenames[\"features_\"+u] = (directory / (f\"features_{u}.pth\"), rank)\n",
    "        rank += 1\n",
    "    return filenames\n",
    "\n",
    "def setup(participants, tmp_dir_name=\"./TMP\"):\n",
    "    num_participants = len(participants)\n",
    "    TMP_DIR = pathlib.Path(tmp_dir_name)\n",
    "    print(f\"Our temporary data will land here: {TMP_DIR}\")\n",
    "    check_and_mkdir(TMP_DIR)\n",
    "    filenames = get_filenames(TMP_DIR, participants)\n",
    "    return TMP_DIR, filenames, num_participants \n",
    "\n",
    "POSSIBLE_PARTICIPANTS = (\"alice, bob, clara, daniel, \" + \n",
    "    \"elina, franz, georg, hilda, ilya, julia, karin, luke, \" +\n",
    "    \"martin, nadia, olaf, peter, queenie, rasmus, sarah, tal, \" +\n",
    "    \"ulyana, valerie, walter, xander, ymir, zorro\").split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our temporary data will land here: TMP_train_on_shared_data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alice', 'bob']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.dir_setup import *\n",
    "\n",
    "len(POSSIBLE_PARTICIPANTS)\n",
    "# Across\n",
    "participants = POSSIBLE_PARTICIPANTS[:2]\n",
    "dir_name = \"./TMP_\" + \"train_on_shared_data\"\n",
    "\n",
    "TMP_DIR, filenames, num_participants = setup(participants, tmp_dir_name=dir_name)\n",
    "DATA_DIR = TMP_DIR / \"data\"\n",
    "participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alice', 'bob']\n",
      "TMP_train_on_shared_data\n",
      "{'features': PosixPath('TMP_train_on_shared_data/features.pth'), 'labels': PosixPath('TMP_train_on_shared_data/labels.pth'), 'b_true': PosixPath('TMP_train_on_shared_data/b_true.pth'), 'test_features': PosixPath('TMP_train_on_shared_data/test_features.pth'), 'targets': PosixPath('TMP_train_on_shared_data/targets.pth'), 'w_true': PosixPath('TMP_train_on_shared_data/w_true.pth'), 'labels_alice': (PosixPath('TMP_train_on_shared_data/labels_alice.pth'), 0), 'features_alice': (PosixPath('TMP_train_on_shared_data/features_alice.pth'), 0), 'labels_bob': (PosixPath('TMP_train_on_shared_data/labels_bob.pth'), 1), 'features_bob': (PosixPath('TMP_train_on_shared_data/features_bob.pth'), 1)}\n"
     ]
    }
   ],
   "source": [
    "print(participants)\n",
    "print(TMP_DIR)\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary (black/white) images\n",
    "\n",
    "https://madflex.de/mnist-with-binary-color/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using train_test ratios: 0.75 : 0.25\n",
      "Train batch size: 750\n",
      "Test batch size: 250\n"
     ]
    }
   ],
   "source": [
    "# MNIST has 60000 images for train\n",
    "#           10000 images for test\n",
    "subset = 1/60\n",
    "train_ratio = 0.75\n",
    "test_ratio = 1 - train_ratio\n",
    "batch_size_train = int((subset * MNIST_SIZE) * train_ratio)\n",
    "batch_size_test = int((subset * MNIST_SIZE) * test_ratio)\n",
    "\n",
    "print(f\"Using train_test ratios: {train_ratio} : {test_ratio}\")\n",
    "print(f\"Train batch size: {batch_size_train}\")\n",
    "print(f\"Test batch size: {batch_size_test}\")\n",
    "\n",
    "black_white_transform = torchvision.transforms.Compose([\n",
    "                                torchvision.transforms.ToTensor(),\n",
    "                                torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                                lambda x: x>0,\n",
    "                                lambda x: x.float(),\n",
    "                             ])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(DATA_DIR, train=True, download=True,\n",
    "                             transform=black_white_transform),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(DATA_DIR, train=False, download=True,\n",
    "                             transform=black_white_transform),\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "train_batches = enumerate(train_loader)\n",
    "test_batches = enumerate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: torch.Size([750, 1, 28, 28]) [CHECK]\n",
      "test set: torch.Size([250, 1, 28, 28]) [CHECK]\n"
     ]
    }
   ],
   "source": [
    "train_idx, digits = next(train_batches)\n",
    "test_idx, digits_test = next(test_batches)\n",
    "\n",
    "#check if tensor shapes match the desired sizes\n",
    "print(f\"train set: {digits[0].shape} [\", end=\"\")\n",
    "if digits[0].shape[0] == batch_size_train:\n",
    "    print(\"CHECK]\")\n",
    "else:\n",
    "    print(\"FAILURE]\")\n",
    "    \n",
    "print(f\"test set: {digits_test[0].shape} [\", end=\"\")\n",
    "if digits_test[0].shape[0] == batch_size_test:\n",
    "    print(\"CHECK]\")\n",
    "else:\n",
    "    print(\"FAILURE]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANMElEQVR4nO3df6xk5V3H8fcHSlOlqLuim3VhS21I/+kfVAk2kSgmtiKJgf5RUmLjNqjbP0Rp4o8SjIFYaxqjrVFjk22KbFGpTbcIWUkpJVRIjC0LUlggFGyWspv90XWtgJq0sF//mLP1ssy9c++c+XXv834lkzlz7syZ7z27n/s8zzln5klVIWnjO2PeBUiaDcMuNcKwS40w7FIjDLvUCMMuNcKwNyzJl5P82qxfq/kw7BtAkgNJfn7edaxGkvuSVJLXzbuW1hh2zUySXwbOmncdrTLsG1iSTUn2JvlWkv/sls877WlvSfLVJC8kuTPJ5iWvf0eSf0ny7SRfS3JZj1p+ELgJ+L1xt6F+DPvGdgbwN8CbgO3A/wJ/ddpzfgW4FtgKvAz8BUCSbcA/AX8EbAZ+B9iT5EdOf5Mk27s/CNtXqOWPgU8AR/r8QhqfYd/Aquo/qmpPVf1PVb0IfAT42dOedltV7a+q/wb+ALg6yZnA+4C7q+ruqjpZVfcC+4ArhrzPN6vqh6rqm8PqSHIx8NPAX07w19MaeZBkA0vy/cDHgcuBTd3qc5KcWVWvdI+fX/KS5xiMqc9l0Bt4T5JfWvLzs4D711jDGcBfA9dX1ctJ1v6LaCIM+8b228BbgZ+qqiNJLgL+DViauPOXLG8HvgscZ/BH4Laq+vWeNfwAcDHwD13Qz+zWH0zynqp6sOf2tUqGfeM4K8kbljx+GTiHwTj9292Bt5uGvO59ST4NHAD+EPhcVb2S5G+Bh5L8AvAlBq36O4Bnq+rgGur6L+DHljw+H/gq8JPAt9awHfXkmH3juJtBsE/dbgb+HPg+Bi31vwJfGPK624BbGRw4ewPwWwBV9TxwJXAjg1A+D/wuQ/7PdAfoXhp2gK4Gjpy68f8BP1pV3xnzd9UY4pdXSG2wZZcaYdilRhh2qRGGXWrETE+9JfFooDRlVTX0yqVeLXuSy5M8neTZJDf02Zak6Rr71Ft3/fTXgXcCB4GHgGuq6skVXmPLLk3ZNFr2SxhcTfWN7uKIzzC4CEPSAuoT9m28+kMUB7t1r5JkZ5J9Sfb1eC9JPU39AF1V7QJ2gd14aZ76tOyHePUnps7r1klaQH3C/hBwYZI3J3k98F7grsmUJWnSxu7Gd19EcB1wD4PPKN9SVU9MrDJJEzXTT705ZpembyoX1UhaPwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSI2Y6ZbO0VN9vNk6GfomqlmHLLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIzzPrqma5SzBWlmvsCc5ALwIvAK8XFUXT6IoSZM3iZb956rq+AS2I2mKHLNLjegb9gK+mOThJDuHPSHJziT7kuzr+V6SekifAyhJtlXVoSQ/CtwL/GZVPbDC8z1a05hpHqDzgzDDVdXQHdOrZa+qQ939MeAO4JI+25M0PWOHPcnZSc45tQy8C9g/qcIkTVafo/FbgDu6rtTrgL+vqi9MpCoJu+mT1mvMvuY3c8zenJ7HhCZYSTumMmaXtH4YdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUY4ZfM6sMjf0LrItenVbNmlRhh2qRGGXWqEYZcaYdilRhh2qRGGXWqE59k3AM9XazVGtuxJbklyLMn+Jes2J7k3yTPd/abplimpr9V0428FLj9t3Q3AfVV1IXBf91jSAhsZ9qp6ADhx2uorgd3d8m7gqsmWJWnSxh2zb6mqw93yEWDLck9MshPYOeb7SJqQ3gfoqqqSLPtpiKraBewCWOl5kqZr3FNvR5NsBejuj02uJEnTMG7Y7wJ2dMs7gDsnU46kacmozyMnuR24DDgXOArcBPwj8FlgO/AccHVVnX4Qb9i27MaPYRX/RjOq5LX6fJ59FK8fGE9VDd1xI8M+SYZ9PIZda7Fc2L1cVmqEYZcaYdilRhh2qRGGXWqEH3FdALM8I7JWi1yb1saWXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRnieXXPjp9pmy5ZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapESPDnuSWJMeS7F+y7uYkh5I82t2umG6ZkvpaTct+K3D5kPUfr6qLutvdky1L0qSNDHtVPQCcmEEtkqaoz5j9uiSPdd38Tcs9KcnOJPuS7OvxXpJ6ymom7ktyAbC3qt7WPd4CHAcK+DCwtaquXcV2nCVwiL6TJ07zixunObGjXzg5HVU1dMeO1bJX1dGqeqWqTgKfBC7pU5yk6Rsr7Em2Lnn4bmD/cs+VtBhGfm98ktuBy4BzkxwEbgIuS3IRg278AeAD0ytx4xvVnR3VlV7kOdTtqi+OVY3ZJ/ZmjtnHsshhHsWwz95Ex+yS1h/DLjXCsEuNMOxSIwy71AinbF4H+p6ak8CWXWqGYZcaYdilRhh2qRGGXWqEYZcaYdilRniefQNY6Ty85+B1ii271AjDLjXCsEuNMOxSIwy71AjDLjXCsEuN8Dz7Budn4XWKLbvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40YGfYk5ye5P8mTSZ5Icn23fnOSe5M8091vmn65mrQkK960cYycsjnJVmBrVT2S5BzgYeAq4P3Aiar6aJIbgE1V9aER2/IKjnWm70U3/sGYvbGnbK6qw1X1SLf8IvAUsA24EtjdPW03gz8AkhbUmsbsSS4A3g58BdhSVYe7Hx0Btky2NEmTtOpr45O8EdgDfLCqXljaPauqWq6LnmQnsLNvoZL6GTlmB0hyFrAXuKeqPtatexq4rKoOd+P6L1fVW0dsxzH7OuOYff0Ze8yewb/Wp4CnTgW9cxewo1veAdzZt0hJ07Oao/GXAg8CjwMnu9U3Mhi3fxbYDjwHXF1VJ0Zsy5Z9nbFlX3+Wa9lX1Y2fFMO+/hj29WfsbrykjcGwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS41Y9fRPapNfBb1x2LJLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9SIkWFPcn6S+5M8meSJJNd3629OcijJo93tiumXK2lcI+dnT7IV2FpVjyQ5B3gYuAq4Gnipqv501W/m/OzS1C03P/vIK+iq6jBwuFt+MclTwLbJlidp2tY0Zk9yAfB24CvdquuSPJbkliSblnnNziT7kuzrV6qkPkZ247/3xOSNwD8DH6mqzyfZAhwHCvgwg67+tSO2YTdemrLluvGrCnuSs4C9wD1V9bEhP78A2FtVbxuxHcMuTdlyYV/N0fgAnwKeWhr07sDdKe8G9vctUtL0rOZo/KXAg8DjwMlu9Y3ANcBFDLrxB4APdAfzVtqWLbs0Zb268ZNi2KXpG7sbL2ljMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSI2Y9ZfNx4Lklj8/t1i2iRa1tUesCaxvXJGt703I/mOnn2V/z5sm+qrp4bgWsYFFrW9S6wNrGNava7MZLjTDsUiPmHfZdc37/lSxqbYtaF1jbuGZS21zH7JJmZ94tu6QZMexSI+YS9iSXJ3k6ybNJbphHDctJciDJ49001HOdn66bQ+9Ykv1L1m1Ocm+SZ7r7oXPszam2hZjGe4Vpxue67+Y9/fnMx+xJzgS+DrwTOAg8BFxTVU/OtJBlJDkAXFxVc78AI8nPAC8Bnz41tVaSPwFOVNVHuz+Um6rqQwtS282scRrvKdW23DTj72eO+26S05+PYx4t+yXAs1X1jar6DvAZ4Mo51LHwquoB4MRpq68EdnfLuxn8Z5m5ZWpbCFV1uKoe6ZZfBE5NMz7XfbdCXTMxj7BvA55f8vggizXfewFfTPJwkp3zLmaILUum2ToCbJlnMUOMnMZ7lk6bZnxh9t0405/35QG617q0qn4C+EXgN7ru6kKqwRhskc6dfgJ4C4M5AA8DfzbPYrppxvcAH6yqF5b+bJ77bkhdM9lv8wj7IeD8JY/P69YthKo61N0fA+5gMOxYJEdPzaDb3R+bcz3fU1VHq+qVqjoJfJI57rtumvE9wN9V1ee71XPfd8PqmtV+m0fYHwIuTPLmJK8H3gvcNYc6XiPJ2d2BE5KcDbyLxZuK+i5gR7e8A7hzjrW8yqJM473cNOPMed/Nffrzqpr5DbiCwRH5fwd+fx41LFPXjwNf625PzLs24HYG3brvMji28avADwP3Ac8AXwI2L1BttzGY2vsxBsHaOqfaLmXQRX8MeLS7XTHvfbdCXTPZb14uKzXCA3RSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXi/wCRgmo0S1HPSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_num = 3\n",
    "plot_digit(digits[0][img_num], digits[1][img_num]) # plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save encrypted data for each participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lib/data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lib/data.py\n",
    "\"\"\"data.py\n",
    "Helper functions for splitting the dataset\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def get_indices(length, num_splits):\n",
    "    step = int(length / num_splits)\n",
    "    return np.arange(0, length+1, step=step, dtype=int)\n",
    "    \n",
    "def split_data(data, frac):\n",
    "    length = len(data[1]) #.shape[0]\n",
    "    split_idx = int(length*frac)\n",
    "    print(f\"Returning: 0 <-1-> {split_idx} <-2->{length}\")\n",
    "    feats_1, labels_1 = data[0][:split_idx], data[1][:split_idx]\n",
    "    feats_2, labels_2 = data[0][split_idx:], data[1][split_idx:]\n",
    "    return (feats_1, labels_1), (feats_2, labels_2)\n",
    "\n",
    "def split_data_even(data, num_splits:int):\n",
    "    length = len(data[1]) #.shape[0]\n",
    "    split_idx = get_indices(length, num_splits)\n",
    "    return [[data[0][start:stop], data[1][start:stop]] for (start, stop) in zip(split_idx[:-1], split_idx[1:])]\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lib/mpc_helpers.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lib/mpc_helpers.py\n",
    "\"\"\"mpc_helpers.py\n",
    "Helper functions for MPC execution\n",
    "\"\"\"\n",
    "\n",
    "def mpc_check(func):\n",
    "    \"\"\"Gathers the return values and evaluates for execution success.\n",
    "    \"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        process_results = func(*args, **kwargs)\n",
    "        if not all(process_results):\n",
    "            print(\"SUCCESS\")\n",
    "        else:\n",
    "            print(\"FAILURE\")\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lib/mpc_tests.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lib/mpc_tests.py\n",
    "\"\"\"mpc_tests.py\n",
    "Some test functions I wrote to test MPC execution.\"\"\"\n",
    "import torch\n",
    "import crypten\n",
    "import crypten.communicator as mpc_comm # the communicator is similar to the MPI communicator for example\n",
    "from crypten import mpc\n",
    "from .mpc_helpers import *\n",
    "\n",
    "world_size = 5\n",
    "        \n",
    "@mpc_check\n",
    "@mpc.run_multiprocess(world_size=world_size)\n",
    "def test():\n",
    "    ws = mpc_comm.get().world_size\n",
    "    rank = mpc_comm.get().get_rank()\n",
    "    print(rank)\n",
    "    tens = torch.tensor([x for x in range(ws+1)])\n",
    "    #for rank in range(ws):\n",
    "    crypten.save(tens, f\"test_{rank}.pth\", src=rank)\n",
    "        #crypten.save_from_party(tens, f\"test_{rank}\", src=rank)\n",
    "\n",
    "@mpc_check\n",
    "@mpc.run_multiprocess(world_size=world_size)\n",
    "def test_load():\n",
    "    ws = mpc_comm.get().world_size\n",
    "    rank = mpc_comm.get().get_rank()\n",
    "    print(rank)\n",
    "    data = []\n",
    "    for rank in range(ws):\n",
    "        data.append(crypten.load(f\"test_{rank}.pth\", src=rank))\n",
    "    print(data[0])\n",
    "    print(data[0].get_plain_text())\n",
    "        \n",
    "def test_solo(world_size=world_size):\n",
    "    tens = torch.tensor([x for x in range(world_size+1)])\n",
    "    for rank in range(world_size):\n",
    "        crypten.save(tens, f\"test_{rank}.pth\", src=rank)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    test()\n",
    "    test_load()\n",
    "    #test_solo()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "\n",
      "43\n",
      "\n",
      "2\n",
      "MPCTensor(\n",
      "\t_tensor=tensor([-2172557661602100065, -8248486143624092936, -4558660403164687987,\n",
      "         7039022768983006833, -8313906410089631684, -4268521608253602023])\n",
      "\tplain_text=HIDDEN\n",
      "\tptype=ptype.arithmetic\n",
      ")MPCTensor(\n",
      "\t_tensor=tensor([ 7912642241335785473, -3620438739574442985,  3367502635828789862,\n",
      "         3278714478180808805, -7511149405755644855, -5686072549534639814])\n",
      "\tplain_text=HIDDEN\n",
      "\tptype=ptype.arithmetic\n",
      ")MPCTensor(\n",
      "\t_tensor=tensor([ 6242375538590409053,  3427794405493272190, -4625541581625966160,\n",
      "        -4726869530904739858, -7372530666278649040,  1462026523063818876])\n",
      "\tplain_text=HIDDEN\n",
      "\tptype=ptype.arithmetic\n",
      ")MPCTensor(\n",
      "\t_tensor=tensor([ 3969357485734658394,  2144106168105361921,  9132555315178058488,\n",
      "         -230083729833152257, -3947910481791341975,  4311825568165893937])\n",
      "\tplain_text=HIDDEN\n",
      "\tptype=ptype.arithmetic\n",
      ")MPCTensor(\n",
      "\t_tensor=tensor([ 2494926469650798761,  6297024309599967346, -3315855966216063131,\n",
      "        -5360783986425726915,  8698752890205978082,  4180742066558856704])\n",
      "\tplain_text=HIDDEN\n",
      "\tptype=ptype.arithmetic\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tensor([0., 1., 2., 3., 4., 5.])tensor([0., 1., 2., 3., 4., 5.])\n",
      "tensor([0., 1., 2., 3., 4., 5.])\n",
      "\n",
      "tensor([0., 1., 2., 3., 4., 5.])\n",
      "tensor([0., 1., 2., 3., 4., 5.])\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "from lib.mpc_tests import *\n",
    "\n",
    "test_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "from lib.data import *\n",
    "from lib.mpc_helpers import *\n",
    "\n",
    "# Split data and save\n",
    "data_batches = split_data_even(digits, num_participants)\n",
    "\n",
    "# Save features, labels for Data Labeling example\n",
    "# All plain text essentially\n",
    "crypten.save(digits[0], filenames[\"features\"])\n",
    "crypten.save(digits[1], filenames[\"labels\"])\n",
    "crypten.save(digits_test[0], filenames[\"test_features\"])\n",
    "crypten.save(digits_test[1], filenames[\"targets\"])\n",
    "    \n",
    "@mpc_check\n",
    "@mpc.run_multiprocess(world_size=num_participants)\n",
    "def save_all_data():\n",
    "    my_rank = mpc_comm.get().get_rank()\n",
    "    world_size = mpc_comm.get().world_size\n",
    "    #print(f\"Hello from {my_rank}\")\n",
    "    \n",
    "    image_batch = data_batches[my_rank][0]\n",
    "    label_batch = data_batches[my_rank][1]\n",
    "    name = participants[my_rank]\n",
    "    \n",
    "    crypten.save(image_batch, filenames[f\"features_{name}\"][0], src=my_rank)\n",
    "    crypten.save(label_batch, filenames[f\"labels_{name}\"][0], src=my_rank)\n",
    "    \n",
    "    #print(f\"{my_rank} is done! Signing off...\")\n",
    "    \n",
    "save_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the mpc.run_multiprocess decorator\n",
    "\n",
    "To execute multi-party computations locally, we provide a `@mpc.run_multiprocess` function decorator, which we developed to execute CrypTen code from a single script. CrypTen follows the standard MPI programming model: it runs a separate process for each party, but each process runs an identical (complete) program. Each process has a rank variable to identify itself.\n",
    "\n",
    "[Docs](https://crypten.readthedocs.io/en/latest/mpctensor.html#communicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lib/jupyter_helpers.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lib/jupyter_helpers.py\n",
    "\"\"\"jupyter_helpers.py\n",
    "\n",
    "\"\"\"\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "def stop_cell():\n",
    "    print((\"Stopping cell execution\"))\n",
    "    raise StopExecution\n",
    "    print(\"This shouldn't appear...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([375, 1, 28, 28])\n",
      "torch.Size([375, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([750, 1, 28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_keys = [x for x in filenames.keys() if \"features_\" in x]\n",
    "label_keys = [x for x in filenames.keys() if \"labels_\" in x]\n",
    "feature_files = [filenames[x] for x in feature_keys]\n",
    "label_files = [filenames[x] for x in label_keys]\n",
    "\n",
    "Xs = [crypten.load(file, src=0) for file, rank in feature_files]\n",
    "for x in Xs:\n",
    "    print(x.shape)\n",
    "# Combine the feature sets: identical to Tutorial 3\n",
    "X = crypten.cat(Xs, dim=0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([750])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ys = [crypten.load(file, src=0) for file, enc_rank in label_files]\n",
    "y = crypten.cat(Ys, dim=0)\n",
    "print(y.shape)\n",
    "pt_y = y.get_plain_text()\n",
    "\n",
    "y_one_hot = torch.nn.functional.one_hot(pt_y.long(), 10)\n",
    "y_one_hot[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MPC encrypted training now!\n",
      "Process 0 says hello!\n",
      "Loading data now...\n",
      "X: <class 'crypten.mpc.mpc.MPCTensor'>\n",
      "Y: <class 'crypten.mpc.mpc.MPCTensor'>\n",
      "Loading model now...\n",
      "Setting up training environment and hyperparameters...\n",
      "Initialization and loading done...starting training now!\n",
      "#----- EPOCH #1 -----#\n",
      "Computing loss...\n",
      "epoch 1 loss: 2.323333740234375\n",
      "Epoch time: 141.3054850101471s\n",
      "#----- EPOCH #2 -----#\n"
     ]
    }
   ],
   "source": [
    "from lib.jupyter_helpers import *\n",
    "# Load a pytorch net\n",
    "from ZeNet.nets import *\n",
    "from time import time\n",
    "TrainNet = Net1 # Don't instantiate yet\n",
    "\n",
    "#stop_cell()\n",
    "# filenames has to be defined\n",
    "feature_keys = [x for x in filenames.keys() if \"features_\" in x]\n",
    "label_keys = [x for x in filenames.keys() if \"labels_\" in x]\n",
    "feature_files = [filenames[x] for x in feature_keys]\n",
    "label_files = [filenames[x] for x in label_keys]\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "# Since labels are public in this use case, we will simply use them from loaded torch tensors\n",
    "#labels = torch.load('/tmp/train_labels.pth')\n",
    "#labels = labels.long()\n",
    "#labels_one_hot = label_eye[labels]\n",
    "\n",
    "#@mpc_check\n",
    "@mpc.run_multiprocess(world_size=num_participants)\n",
    "def run_encrypted_training():\n",
    "    rank = mpc_comm.get().get_rank()\n",
    "    # Load data:\n",
    "    #x_alice_enc = crypten.load('/tmp/alice_train.pth', src=ALICE)\n",
    "    #x_bob_enc = crypten.load('/tmp/bob_train.pth', src=BOB)\n",
    "\n",
    "    if rank == 0:\n",
    "        print(f\"Process {rank} says hello!\")\n",
    "        print(f\"Loading data now...\")\n",
    "    Xs = [crypten.load(file, src=enc_rank) for file, enc_rank in feature_files]\n",
    "    Ys = [crypten.load(file, src=enc_rank) for file, enc_rank in label_files]\n",
    "    \n",
    "    X = crypten.cat(Xs, dim=0)\n",
    "    y = crypten.cat(Ys, dim=0)\n",
    "    del Ys \n",
    "    del Xs\n",
    "    y_one_hot = crypten.cryptensor(torch.nn.functional.one_hot(y.get_plain_text().long(), 10))\n",
    "    if rank == 0:\n",
    "        print(f\"X: {type(X)}\")\n",
    "        print(f\"Y: {type(y)}\")\n",
    "        \n",
    "    if rank == 0:\n",
    "        print(\"Loading model now...\")\n",
    "    # Initialize a plaintext model and convert to CrypTen model\n",
    "    #dummy_input = X[0]\n",
    "    dummy_input = torch.empty(1, 1, 28, 28)\n",
    "    model = crypten.nn.from_pytorch(TrainNet(), dummy_input)\n",
    "    model.encrypt()\n",
    "    \n",
    "    # Set train mode\n",
    "    model.train()\n",
    "  \n",
    "    # Define a loss function\n",
    "    #criterion = crypten.nn.MSELoss()\n",
    "    criterion = crypten.nn.CrossEntropyLoss()\n",
    "\n",
    "    if rank == 0:\n",
    "        print(\"Setting up training environment and hyperparameters...\")\n",
    "    # Define training parameters\n",
    "    learning_rate = 0.001\n",
    "    epochs = 10\n",
    "    #batch_size = 10\n",
    "    #num_batches = x_combined_enc.size(0) // batch_size\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(f\"Initialization and loading done...starting training now!\")\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        if rank == 0:\n",
    "            print(f\"#----- EPOCH #{epoch} -----#\")\n",
    "            start = time()\n",
    "        model.zero_grad()\n",
    "        output = model(X)\n",
    "        if rank == 0:\n",
    "            print(\"Computing loss...\")\n",
    "        \n",
    "        if output.shape != y_one_hot.shape:\n",
    "            if rank == 0:\n",
    "                print(\"output and labels have unequal shape!\")\n",
    "                print(f\"output: {output.shape}\")\n",
    "                print(f\"y: {y_one_hot.shape}\")\n",
    "            return -1\n",
    "        loss = criterion(output, y_one_hot)\n",
    "        pt_loss = loss.get_plain_text()\n",
    "        if rank == 0:\n",
    "            print(f\"epoch {epoch} loss: {pt_loss}\")\n",
    "        loss.backward()\n",
    "        model.update_parameters(learning_rate)\n",
    "        if rank == 0:\n",
    "            stop = time()\n",
    "            print(f\"Epoch time: {stop - start}s\")\n",
    "    return 0\n",
    "\n",
    "print(\"Starting MPC encrypted training now!\")\n",
    "run_encrypted_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.jupyter_helpers import *\n",
    "# Load a pytorch net\n",
    "from ZeNet.nets import *\n",
    "TrainNet = Net1 # Don't instantiate yet\n",
    "\n",
    "#stop_cell()\n",
    "# filenames has to be defined\n",
    "feature_keys = [x for x in filenames.keys() if \"features_\" in x]\n",
    "label_keys = [x for x in filenames.keys() if \"labels_\" in x]\n",
    "feature_files = [filenames[x] for x in feature_keys]\n",
    "label_files = [filenames[x] for x in label_keys]\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "# Since labels are public in this use case, we will simply use them from loaded torch tensors\n",
    "#labels = torch.load('/tmp/train_labels.pth')\n",
    "#labels = labels.long()\n",
    "#labels_one_hot = label_eye[labels]\n",
    "\n",
    "@mpc_check\n",
    "@mpc.run_multiprocess(world_size=num_participants)\n",
    "def run_encrypted_training():\n",
    "    rank = mpc_comm.get().get_rank()\n",
    "    # Load data:\n",
    "    #x_alice_enc = crypten.load('/tmp/alice_train.pth', src=ALICE)\n",
    "    #x_bob_enc = crypten.load('/tmp/bob_train.pth', src=BOB)\n",
    "\n",
    "    if rank == 0:\n",
    "        print(f\"Process {rank} says hello!\")\n",
    "        print(f\"Loading data now...\")\n",
    "    Xs = [crypten.load(file, src=enc_rank) for file, enc_rank in feature_files]\n",
    "    X = crypten.cat(Xs, dim=0)\n",
    "    Ys = [crypten.load(file, src=enc_rank) for file, enc_rank in label_files]\n",
    "    y = crypten.cat(Ys, dim=0)\n",
    "    \n",
    "    \n",
    "    if rank == 0:\n",
    "        print(\"Loading model now...\")\n",
    "    # Initialize a plaintext model and convert to CrypTen model\n",
    "    #dummy_input = X[0]\n",
    "    dummy_input = torch.empty(1, 1, 28, 28)\n",
    "    model = crypten.nn.from_pytorch(TrainNet(), dummy_input)\n",
    "    #model.encrypt()\n",
    "    \n",
    "    # Set train mode\n",
    "    model.train()\n",
    "  \n",
    "    # Define a loss function\n",
    "    criterion = crypten.nn.MSELoss()\n",
    "    #criterion = crypten.nn.CrossEntropyLoss()\n",
    "\n",
    "    if rank == 0:\n",
    "        print(\"Setting up training environment and hyperparameters...\")\n",
    "    # Define training parameters\n",
    "    learning_rate = 0.001\n",
    "    epochs = 2\n",
    "    #batch_size = 10\n",
    "    #num_batches = x_combined_enc.size(0) // batch_size\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(f\"Initialization and loading done...starting training now!\")\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        if rank == 0:\n",
    "            print(f\"#----- EPOCH #{epoch} -----#\")\n",
    "        model.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        pt_loss = loss.get_plain_text()\n",
    "        if rank == 0:\n",
    "            print(f\"epoch {epoch} loss: {pt_loss}\")\n",
    "        loss.backward()\n",
    "        model.update_parameters(learning_rate)\n",
    "\n",
    "run_encrypted_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some unused stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused!\n",
    "def load_enc_data(X_files, y_files):\n",
    "    # Load images\n",
    "    X = []\n",
    "    for file, rank in X_files:\n",
    "        X.append(crypten.load(file, src=rank))\n",
    "        \n",
    "    # Load labels\n",
    "    y = []\n",
    "    for file, rank in y_files:\n",
    "        y.append(crypten.load(file, src=rank))\n",
    "        \n",
    "    return X, y\n",
    "\n",
    "def load_model(Net, dummy_input, ENC_RANK):\n",
    "    # (1, 1, 28, 28)\n",
    "    private_model = crypten.nn.from_pytorch(Net, dummy_input)\n",
    "    private_model.encrypt(src=ENC_RANK)\n",
    "    return private_model\n",
    "\n",
    "def train_model(model, X, y, epochs=10, learning_rate=0.05):\n",
    "    criterion = crypten.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        print(f\"epoch {epoch} loss: {loss.get_plain_text()}\")\n",
    "        loss.backward()\n",
    "        model.update_parameters(learning_rate)\n",
    "    return model\n",
    "\n",
    "def evaluate_model():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.load('/tmp/bob_test_labels.pth').long()\n",
    "count = 100 # For illustration purposes, we'll use only 100 samples for classification\n",
    "\n",
    "@mpc.run_multiprocess(world_size=2)\n",
    "def encrypt_model_and_data():\n",
    "    # Load pre-trained model to Alice\n",
    "    model = crypten.load('models/tutorial4_alice_model.pth', dummy_model=dummy_model, src=ALICE)\n",
    "    \n",
    "    # Encrypt model from Alice \n",
    "    dummy_input = torch.empty((1, 784))\n",
    "    private_model = crypten.nn.from_pytorch(model, dummy_input)\n",
    "    private_model.encrypt(src=ALICE)\n",
    "    \n",
    "    # Load data to Bob\n",
    "    data_enc = crypten.load('/tmp/bob_test.pth', src=BOB)\n",
    "    data_enc2 = data_enc[:count]\n",
    "    data_flatten = data_enc2.flatten(start_dim=1)\n",
    "\n",
    "    # Classify the encrypted data\n",
    "    private_model.eval()\n",
    "    output_enc = private_model(data_flatten)\n",
    "    \n",
    "    # Compute the accuracy\n",
    "    output = output_enc.get_plain_text()\n",
    "    accuracy = compute_accuracy(output, labels[:count])\n",
    "    print(\"\\tAccuracy: {0:.4f}\".format(accuracy.item()))\n",
    "    \n",
    "encrypt_model_and_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on different machines\n",
    "\n",
    "Tricky: https://github.com/facebookresearch/CrypTen/issues/104\n",
    "\n",
    "Scripts: <https://github.com/facebookresearch/CrypTen/tree/master/scripts>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML_2020)",
   "language": "python",
   "name": "ml_2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
