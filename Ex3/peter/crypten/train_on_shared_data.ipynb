{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's put it together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile train_model.py\n",
    "\"\"\"train_model.py\n",
    "\n",
    "I'm testing if I can sensibly condense a jupyter notebook into a script via %%writefile cell magic.\n",
    "\"\"\"\n",
    "# Load parent folders into path\n",
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "# Import some config variables\n",
    "from config import PETER_ROOT, DATA_DIR, MNIST_SIZE\n",
    "\n",
    "\n",
    "# Plotting\n",
    "from plot_mnist import plot_batch, plot_digit\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import crypten\n",
    "import crypten.communicator as mpc_comm # the communicator is similar to the MPI communicator for example\n",
    "from crypten import mpc\n",
    "\n",
    "assert sys.version_info[0] == 3 and sys.version_info[1] == 7, \"python 3.7 is required!\"\n",
    "\n",
    "print(f\"Okay, good! You have: {sys.version_info[:3]}\")\n",
    "# Now we can init crypten!\n",
    "crypten.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lib/dir_setup.py\n",
    "\"\"\"dir_setup.py\n",
    "\n",
    "Functions for data directory setup and generation of filename dictionary.\n",
    "\"\"\"\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "def rm_files_in_dir(directoy:pathlib.Path, recursive=False):\n",
    "    if not directory.exists():\n",
    "        print(f\"{directory} does not exist\")\n",
    "    else:\n",
    "        if recursive:\n",
    "            # Simple non-recursive glob --> doesn't look into subdirectories\n",
    "            for file in [x for x in directory.glob(\"*\") if x.is_file()]:\n",
    "                file.unlink()\n",
    "            print(f\"{directory} cleaned!\")\n",
    "        else:\n",
    "            # Use recursive glob\n",
    "            for file in [x for x in directory.rglob(\"*\") if x.is_file()]:\n",
    "                file.unlink()\n",
    "            print(f\"{directory} and it's subdirectories cleaned!\")\n",
    "\n",
    "def check_and_mkdir(directory:pathlib.Path):\n",
    "    if not directory.exists():\n",
    "        print(f\"Directory {directory} created.\")\n",
    "        directory.mkdir()\n",
    "\n",
    "def rm_dir(directory:pathlib.Path):\n",
    "    shutil.rmtree(directory)\n",
    "    \n",
    "def get_filenames(directory:pathlib.Path, participants):\n",
    "    # Specify file locations to save each piece of data\n",
    "    filenames = {\n",
    "        \"features\": directory / \"features.pth\",\n",
    "        \"labels\": directory / \"labels.pth\",\n",
    "        \"b_true\": directory / \"b_true.pth\",\n",
    "        \"test_features\": directory / \"test_features.pth\",\n",
    "        \"targets\": directory / \"targets.pth\",\n",
    "        \"w_true\": directory / \"w_true.pth\",\n",
    "    }\n",
    "\n",
    "    rank = 0\n",
    "    for u in participants:\n",
    "        filenames[\"labels_\"+u] = (directory / (f\"labels_{u}.pth\"), rank)\n",
    "        filenames[\"features_\"+u] = (directory / (f\"features_{u}.pth\"), rank)\n",
    "        rank += 1\n",
    "    return filenames\n",
    "\n",
    "def setup(participants, tmp_dir_name=\"./TMP\"):\n",
    "    num_participants = len(participants)\n",
    "    TMP_DIR = pathlib.Path(tmp_dir_name)\n",
    "    print(f\"Our temporary data will land here: {TMP_DIR}\")\n",
    "    check_and_mkdir(TMP_DIR)\n",
    "    filenames = get_filenames(TMP_DIR, participants)\n",
    "    return TMP_DIR, filenames, num_participants \n",
    "\n",
    "POSSIBLE_PARTICIPANTS = (\"alice, bob, clara, daniel, \" + \n",
    "    \"elina, franz, georg, hilda, ilya, julia, karin, luke, \" +\n",
    "    \"martin, nadia, olaf, peter, queenie, rasmus, sarah, tal, \" +\n",
    "    \"ulyana, valerie, walter, xander, ymir, zorro\").split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.dir_setup import *\n",
    "\n",
    "len(POSSIBLE_PARTICIPANTS)\n",
    "# Across\n",
    "participants = POSSIBLE_PARTICIPANTS[:2]\n",
    "dir_name = \"./TMP_\" + \"train_on_shared_data\"\n",
    "\n",
    "TMP_DIR, filenames, num_participants = setup(participants, tmp_dir_name=dir_name)\n",
    "DATA_DIR = TMP_DIR / \"data\"\n",
    "participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(participants)\n",
    "print(TMP_DIR)\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary (black/white) images\n",
    "\n",
    "https://madflex.de/mnist-with-binary-color/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 1/60\n",
    "train_ratio = 0.75\n",
    "test_ratio = 1 - train_ratio\n",
    "batch_size_train = int((subset * MNIST_SIZE) * train_ratio)\n",
    "batch_size_test = int((subset * MNIST_SIZE) * test_ratio)\n",
    "\n",
    "print(f\"Using train_test ratios: {train_ratio} : {test_ratio}\")\n",
    "print(f\"Train batch size: {batch_size_train}\")\n",
    "print(f\"Test batch size: {batch_size_test}\")\n",
    "\n",
    "black_white_transform = torchvision.transforms.Compose([\n",
    "                                torchvision.transforms.ToTensor(),\n",
    "                                torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                                lambda x: x>0,\n",
    "                                lambda x: x.float(),\n",
    "                             ])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(DATA_DIR, train=True, download=True,\n",
    "                             transform=black_white_transform),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(DATA_DIR, train=False, download=True,\n",
    "                             transform=black_white_transform),\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "train_batches = enumerate(train_loader)\n",
    "test_batches = enumerate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, digits = next(train_batches)\n",
    "test_idx, digits_test = next(test_batches)\n",
    "\n",
    "#check if tensor shapes match the desired sizes\n",
    "print(f\"train set: {digits[0].shape} [\", end=\"\")\n",
    "if digits[0].shape[0] == batch_size_train:\n",
    "    print(\"CHECK]\")\n",
    "else:\n",
    "    print(\"FAILURE]\")\n",
    "    \n",
    "print(f\"test set: {digits_test[0].shape} [\", end=\"\")\n",
    "if digits_test[0].shape[0] == batch_size_test:\n",
    "    print(\"CHECK]\")\n",
    "else:\n",
    "    print(\"FAILURE]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = 1\n",
    "plot_digit(digits[0][img_num], digits[1][img_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save encrypted data for each participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lib/data.py\n",
    "\"\"\"data.py\n",
    "Helper functions for splitting the dataset\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def get_indices(length, num_splits):\n",
    "    step = int(length / num_splits)\n",
    "    return np.arange(0, length+1, step=step, dtype=int)\n",
    "    \n",
    "def split_data(data, frac):\n",
    "    length = len(data[1]) #.shape[0]\n",
    "    split_idx = int(length*frac)\n",
    "    print(f\"Returning: 0 <-1-> {split_idx} <-2->{length}\")\n",
    "    feats_1, labels_1 = data[0][:split_idx], data[1][:split_idx]\n",
    "    feats_2, labels_2 = data[0][split_idx:], data[1][split_idx:]\n",
    "    return (feats_1, labels_1), (feats_2, labels_2)\n",
    "\n",
    "def split_data_even(data, num_splits:int):\n",
    "    length = len(data[1]) #.shape[0]\n",
    "    split_idx = get_indices(length, num_splits)\n",
    "    return [[data[0][start:stop], data[1][start:stop]] for (start, stop) in zip(split_idx[:-1], split_idx[1:])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lib/mpc_helpers.py\n",
    "\"\"\"mpc_helpers.py\n",
    "Helper functions for MPC execution\n",
    "\"\"\"\n",
    "\n",
    "def mpc_check(func):\n",
    "    \"\"\"Gathers the return values and evaluates for execution success.\n",
    "    \"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        process_results = func(*args, **kwargs)\n",
    "        if not all(process_results):\n",
    "            print(\"SUCCESS\")\n",
    "        else:\n",
    "            print(\"FAILURE\")\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lib/mpc_tests.py\n",
    "\"\"\"mpc_tests.py\n",
    "Some test functions I wrote to test MPC execution.\"\"\"\n",
    "import torch\n",
    "import crypten\n",
    "import crypten.communicator as mpc_comm # the communicator is similar to the MPI communicator for example\n",
    "from crypten import mpc\n",
    "\n",
    "world_size = 5\n",
    "        \n",
    "@mpc_check\n",
    "@mpc.run_multiprocess(world_size=world_size)\n",
    "def test():\n",
    "    ws = mpc_comm.get().world_size\n",
    "    rank = mpc_comm.get().get_rank()\n",
    "    print(rank)\n",
    "    tens = torch.tensor([x for x in range(ws+1)])\n",
    "    #for rank in range(ws):\n",
    "    crypten.save(tens, f\"test_{rank}.pth\", src=rank)\n",
    "        #crypten.save_from_party(tens, f\"test_{rank}\", src=rank)\n",
    "\n",
    "@mpc_check\n",
    "@mpc.run_multiprocess(world_size=world_size)\n",
    "def test_load(world_size=3):\n",
    "    ws = mpc_comm.get().world_size\n",
    "    rank = mpc_comm.get().get_rank()\n",
    "    print(rank)\n",
    "    data = []\n",
    "    for rank in range(ws):\n",
    "        data.append(crypten.load(f\"test_{rank}.pth\", src=rank))\n",
    "    print(data[0])\n",
    "    print(data[0].get_plain_text())\n",
    "        \n",
    "def test_solo(world_size=world_size):\n",
    "    tens = torch.tensor([x for x in range(world_size+1)])\n",
    "    for rank in range(world_size):\n",
    "        crypten.save(tens, f\"test_{rank}.pth\", src=rank)\n",
    "\n",
    "test()\n",
    "test_load()\n",
    "#test_solo()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data import *\n",
    "from lib.mpc_helpers import *\n",
    "\n",
    "# Split data and save\n",
    "data_batches = split_data_even(digits, num_participants)\n",
    "\n",
    "# Save features, labels for Data Labeling example\n",
    "# All plain text essentially\n",
    "crypten.save(digits[0], filenames[\"features\"])\n",
    "crypten.save(digits[1], filenames[\"labels\"])\n",
    "crypten.save(digits_test[0], filenames[\"test_features\"])\n",
    "crypten.save(digits_test[1], filenames[\"targets\"])\n",
    "    \n",
    "@mpc_check\n",
    "@mpc.run_multiprocess(world_size=num_participants)\n",
    "def save_all_data():\n",
    "    my_rank = mpc_comm.get().get_rank()\n",
    "    world_size = mpc_comm.get().world_size\n",
    "    print(f\"Hello from {my_rank}\")\n",
    "    \n",
    "    image_batch = data_batches[my_rank][0]\n",
    "    label_batch = data_batches[my_rank][1]\n",
    "    name = participants[my_rank]\n",
    "    \n",
    "    crypten.save(image_batch, filenames[f\"features_{name}\"][0], src=my_rank)\n",
    "    crypten.save(label_batch, filenames[f\"labels_{name}\"][0], src=my_rank)\n",
    "    \n",
    "    print(f\"{my_rank} is done! Signing off...\")\n",
    "    \n",
    "save_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the mpc.run_multiprocess decorator\n",
    "\n",
    "To execute multi-party computations locally, we provide a `@mpc.run_multiprocess` function decorator, which we developed to execute CrypTen code from a single script. CrypTen follows the standard MPI programming model: it runs a separate process for each party, but each process runs an identical (complete) program. Each process has a rank variable to identify itself.\n",
    "\n",
    "[Docs](https://crypten.readthedocs.io/en/latest/mpctensor.html#communicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lib/jupyter_helpers.py\n",
    "\"\"\"jupyter_helpers.py\n",
    "\n",
    "\"\"\"\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "def stop_cell():\n",
    "    print((\"Stopping cell execution\"))\n",
    "    raise StopExecution\n",
    "    print(\"This shouldn't appear...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = [x for x in filenames.keys() if \"features_\" in x]\n",
    "label_keys = [x for x in filenames.keys() if \"labels_\" in x]\n",
    "feature_files = [filenames[x] for x in feature_keys]\n",
    "label_files = [filenames[x] for x in label_keys]\n",
    "\n",
    "Xs = [crypten.load(file, src=0) for file, rank in feature_files]\n",
    "for x in Xs:\n",
    "    print(x.shape)\n",
    "# Combine the feature sets: identical to Tutorial 3\n",
    "X = crypten.cat(Xs, dim=0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.jupyter_helpers import *\n",
    "# Load a pytorch net\n",
    "import ZeNet\n",
    "TrainNet = ZeNet.nets.Net1 # Don't instantiate yet\n",
    "\n",
    "stop_cell()\n",
    "# filenames has to be defined\n",
    "feature_keys = [x for x in filenames.keys() if \"features_\" in x]\n",
    "label_keys = [x for x in filenames.keys() if \"labels_\" in x]\n",
    "feature_files = [filenames[x] for x in feature_keys]\n",
    "label_files = [filenames[x] for x in label_keys]\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "# Since labels are public in this use case, we will simply use them from loaded torch tensors\n",
    "labels = torch.load('/tmp/train_labels.pth')\n",
    "labels = labels.long()\n",
    "labels_one_hot = label_eye[labels]\n",
    "\n",
    "@mpc.run_multiprocess(world_size=num_participants)\n",
    "def run_encrypted_training():\n",
    "    rank = comm.get().get_rank()\n",
    "    # Load data:\n",
    "    #x_alice_enc = crypten.load('/tmp/alice_train.pth', src=ALICE)\n",
    "    #x_bob_enc = crypten.load('/tmp/bob_train.pth', src=BOB)\n",
    "    Xs = [crypten.load(file, src=rank) for file, rank in feature_files]\n",
    "    \n",
    "    # Combine the feature sets: identical to Tutorial 3\n",
    "    x_combined_enc = crypten.cat([x_alice_enc, x_bob_enc], dim=2)\n",
    "    \n",
    "    # Reshape to match the network architecture\n",
    "    x_combined_enc = x_combined_enc.unsqueeze(1)\n",
    "    \n",
    "    # Initialize a plaintext model and convert to CrypTen model\n",
    "    model = crypten.nn.from_pytorch(TrainNet(), dummy_input)\n",
    "    #model.encrypt()\n",
    "    \n",
    "    # Set train mode\n",
    "    model.train()\n",
    "  \n",
    "    # Define a loss function\n",
    "    loss = crypten.nn.MSELoss()\n",
    "    #loss = crypten.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Define training parameters\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 2\n",
    "    batch_size = 10\n",
    "    num_batches = x_combined_enc.size(0) // batch_size\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        print(f\"epoch {epoch} loss: {loss.get_plain_text()}\")\n",
    "        loss.backward()\n",
    "        model.update_parameters(learning_rate)\n",
    "    \n",
    "    for i in range(num_epochs):  \n",
    "        # Print once for readability\n",
    "        if rank == 0:\n",
    "            print(f\"Epoch {i} in progress:\")       \n",
    "        \n",
    "        for batch in range(num_batches):\n",
    "            # define the start and end of the training mini-batch\n",
    "            start, end = batch * batch_size, (batch + 1) * batch_size\n",
    "                                    \n",
    "            # construct CrypTensors out of training examples / labels\n",
    "            x_train = x_combined_enc[start:end]\n",
    "            y_batch = labels_one_hot[start:end]\n",
    "            y_train = crypten.cryptensor(y_batch)\n",
    "            \n",
    "            # perform forward pass:\n",
    "            output = model(x_train)\n",
    "            loss_value = loss(output, y_train)\n",
    "            \n",
    "            # set gradients to \"zero\" \n",
    "            model.zero_grad()\n",
    "\n",
    "            # perform backward pass: \n",
    "            loss_value.backward()\n",
    "\n",
    "            # update parameters\n",
    "            model.update_parameters(learning_rate)\n",
    "            \n",
    "            # Print progress every batch:\n",
    "            batch_loss = loss_value.get_plain_text()\n",
    "            if rank == 0:\n",
    "                print(f\"\\tBatch {(batch + 1)} of {num_batches} Loss {batch_loss.item():.4f}\")\n",
    "\n",
    "run_encrypted_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some unused stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused!\n",
    "def load_enc_data(X_files, y_files):\n",
    "    # Load images\n",
    "    X = []\n",
    "    for file, rank in X_files:\n",
    "        X.append(crypten.load(file, src=rank))\n",
    "        \n",
    "    # Load labels\n",
    "    y = []\n",
    "    for file, rank in y_files:\n",
    "        y.append(crypten.load(file, src=rank))\n",
    "        \n",
    "    return X, y\n",
    "\n",
    "def load_model(Net, dummy_input, ENC_RANK):\n",
    "    # (1, 1, 28, 28)\n",
    "    private_model = crypten.nn.from_pytorch(Net, dummy_input)\n",
    "    private_model.encrypt(src=ENC_RANK)\n",
    "    return private_model\n",
    "\n",
    "def train_model(model, X, y, epochs=10, learning_rate=0.05):\n",
    "    criterion = crypten.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        print(f\"epoch {epoch} loss: {loss.get_plain_text()}\")\n",
    "        loss.backward()\n",
    "        model.update_parameters(learning_rate)\n",
    "    return model\n",
    "\n",
    "def evaluate_model():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.load('/tmp/bob_test_labels.pth').long()\n",
    "count = 100 # For illustration purposes, we'll use only 100 samples for classification\n",
    "\n",
    "@mpc.run_multiprocess(world_size=2)\n",
    "def encrypt_model_and_data():\n",
    "    # Load pre-trained model to Alice\n",
    "    model = crypten.load('models/tutorial4_alice_model.pth', dummy_model=dummy_model, src=ALICE)\n",
    "    \n",
    "    # Encrypt model from Alice \n",
    "    dummy_input = torch.empty((1, 784))\n",
    "    private_model = crypten.nn.from_pytorch(model, dummy_input)\n",
    "    private_model.encrypt(src=ALICE)\n",
    "    \n",
    "    # Load data to Bob\n",
    "    data_enc = crypten.load('/tmp/bob_test.pth', src=BOB)\n",
    "    data_enc2 = data_enc[:count]\n",
    "    data_flatten = data_enc2.flatten(start_dim=1)\n",
    "\n",
    "    # Classify the encrypted data\n",
    "    private_model.eval()\n",
    "    output_enc = private_model(data_flatten)\n",
    "    \n",
    "    # Compute the accuracy\n",
    "    output = output_enc.get_plain_text()\n",
    "    accuracy = compute_accuracy(output, labels[:count])\n",
    "    print(\"\\tAccuracy: {0:.4f}\".format(accuracy.item()))\n",
    "    \n",
    "encrypt_model_and_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on different machines\n",
    "\n",
    "Tricky: https://github.com/facebookresearch/CrypTen/issues/104\n",
    "\n",
    "Scripts: <https://github.com/facebookresearch/CrypTen/tree/master/scripts>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML_2020)",
   "language": "python",
   "name": "ml_2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
