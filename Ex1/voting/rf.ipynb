{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('ML_2020': venv)",
   "metadata": {
    "interpreter": {
     "hash": "d6f8d2b41179c5e5fc034bbc40427a4395636c4d26988e51920bd3cc303b8725"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import itertools\n",
    "import pathlib\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Scalars\n",
    "from sklearn.preprocessing import StandardScaler,PowerTransformer,MinMaxScaler,QuantileTransformer,normalize\n",
    "# Features\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "\n",
    "# required for importin modules from other directories\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "from common import misc\n",
    "from common.data_parser import *\n",
    "from common.model_trainer import *\n",
    "from common.misc import *\n",
    "from config import *\n",
    "from functions import *\n",
    "\n",
    "# NEW --> contains plot_params, plot_confusion_matrix and plot_corr_heatmap\n",
    "from common.plotting import *\n",
    "\n",
    "plt.style.use(\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter setup for this notebook\n",
    "MODEL = RFC\n",
    "MODEL_TYPE = \"RFC\"\n",
    "params = {\n",
    "    \"n_estimators\": [1, 8, 10, 12, 15, 20, 50, 100,  1000],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "TEST_SIZE = 0.25\n",
    "RND_STATE = 42\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename function\n",
    "def get_fname(force_filename:str=None, file_format:str=\"pdf\"):\n",
    "    \"\"\"Calculate filename based on parameter and variable values\n",
    "    OR\n",
    "    force a filenamme by appending it to the OUT_DIR set above\n",
    "    \"\"\"\n",
    "    if force_filename:\n",
    "        return OUT_DIR + force_filename\n",
    "\n",
    "    return OUT_DIR + f\"{MODEL_TYPE}_{SCALER_NAME}.{file_format}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = parse_congressional_voting(\"train\")\n",
    "df_raw.info()"
   ]
  },
  {
   "source": [
    "# FIRST TEST"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup test specific parameters/variables here\n",
    "\n",
    "scaler = StandardScaler() # None\n",
    "SCALER_NAME = \"standard\"\n",
    "\n",
    "# Or also modeltrainer parameters\n",
    "eval_func = accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data and do split\n",
    "fname = get_fname()\n",
    "\n",
    "x, y  = process_voting(df_raw, answer_mapping=DEF_MAPPING, scaler=scaler, ret_xy=True)\n",
    "# OR\n",
    "#df = process_voting(df_raw, answer_mapping=DEF_MAPPING, scaler=None, ret_xy=False)\n",
    "#display(df.info())\n",
    "#x, y = df[VOTING_FEATS], df[VOTING_TARGET]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=TEST_SIZE, random_state=RND_STATE)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate modeltrainer and train models\n",
    "modeltrainer = ModelTrainer(\n",
    "    MODEL, \n",
    "    params, \n",
    "    x_train, y_train, x_test, y_test, \n",
    "    eval_func,\n",
    "    thread_cnt=4\n",
    "    )\n",
    "modeltrainer.train()\n",
    "# Setup cm config if wanted\n",
    "# modeltrainer.cm_setup([0, 1])\n",
    "# or\n",
    "modeltrainer.cm_setup(VOTING_CLASSES) # VOTING_CLASSES = [\"democrat\", \"republican\"]\n",
    "\n",
    "#modeltrainer.save_result(\"out/knn_params.csv\")\n",
    "result = modeltrainer.result\n",
    "result.head()\n",
    "\n",
    "SCORES = \"accuracy\"\n",
    "# if fileName is set, make sure that the directory exists\n",
    "plot_params(result, scores=SCORES, fileName=fname, ylims=(0.4,1.1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also give a modified version of params dict to plot less!\n",
    "param2 = {'n_estimators': [1, 8, 10, 12, 15, 20, 50, 100, 1000],\n",
    " 'max_features': ['sqrt'],\n",
    " 'criterion': ['gini', 'entropy']}\n",
    "\n",
    " # function returns the fig, so you can do smth with that\n",
    "fig = plot_params(result, scores=\"inference_time\", params=param2, ylims=(0,0.15));\n"
   ]
  },
  {
   "source": [
    "# Confusion matrices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = modeltrainer.cms\n",
    "\n",
    "df_results = modeltrainer.result\n",
    "\n",
    "display(modeltrainer.cms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer.plot_confusion_matrix(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or like this\n",
    "plot_confusion_matrix(cms[0][1], VOTING_CLASSES, normalize=True, title=\"Confusion matrix\", cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}