{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "# load different classifieres\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# preprocessing \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# for selection the right path\n",
    "import os,sys,inspect,pathlib\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "\n",
    "from common import misc\n",
    "from common.data_parser import *\n",
    "from common.model_trainer import *\n",
    "from common.misc import *\n",
    "from config import *\n",
    "from common.plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = pathlib.Path(os.getcwd()).parent\n",
    "if str(module_path) not in sys.path:\n",
    "    sys.path.append(str(module_path))\n",
    "print(sys.path)\n",
    "\n",
    "from common.dataset_grabber import get_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath_train = get_data_path(\"Congressional_Voting\", \"CongressionalVotingID.shuf.lrn.csv\")\n",
    "display(datapath_train)\n",
    "datapath_test = get_data_path(\"Congressional_Voting\", \"CongressionalVotingID.shuf.tes.csv\")\n",
    "display(datapath_test)\n",
    "datapath_examp = get_data_path(\"Congressional_Voting\", \"CongressionalVotingID.shuf.sol.ex.csv\")\n",
    "display(datapath_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "Data consinst out of of class for the classification and the instances are mostly \"y,n,unknown\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(datapath_train).drop(\"ID\",axis = 1)\n",
    "df_test = pd.read_csv(datapath_test).drop(\"ID\",axis = 1)\n",
    "\n",
    "df_train = df_train.rename(columns={\"class\": \"Class\"})\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.replace(\"n\",-1)\n",
    "df_train = df_train.replace(\"y\",1)\n",
    "df_train = df_train.replace(\"unknown\",0)\n",
    "\n",
    "\n",
    "df_test = df_test.replace(\"n\",-1)\n",
    "df_test = df_test.replace(\"y\",1)\n",
    "df_test = df_test.replace(\"unknown\",0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_lrn = df_train.loc[:,\"handicapped-infants\":]\n",
    "X_lrn = df_train.loc[:,\"handicapped-infants\":]\n",
    "Y_lrn = df_train.loc[:,\"Class\":\"Class\"]\n",
    "#df_test = df_test.loc[:,red_list[1]:red_list[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_lrn, Y_lrn, test_size=0.4) #random noch einf√ºgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classifierer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = MLP\n",
    "MODEL_TYPE = \"MLP\"\n",
    "params = {\n",
    "    \"alpha\" : [1e-3,1e-2,1e-1,1,1e1], \n",
    "    \"hidden_layer_sizes\" : [(20,20),(50,50),(100,100)],\n",
    "    \"solver\" : [\"adam\",\"lbfgs\"],\n",
    "    \"activation\" : [\"tanh\", \"relu\"]\n",
    "    }\n",
    "SCORES = \"accuracy\"\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\"\n",
    "\n",
    "fname = OUT_DIR + f\"{MODEL_TYPE}_{SCORES}.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGX = True\n",
    "YLIMS = (0.5, 1)\n",
    "\n",
    "\n",
    "def plot_params(results, scores=\"score\", fileName=None, params=params, ylims=YLIMS):\n",
    "    param_keys = list(params)\n",
    "    first_key = param_keys[0]\n",
    "    rest = param_keys[1:]\n",
    "\n",
    "    plt.style.use('seaborn')\n",
    "    if isinstance(scores, str):\n",
    "        fix, ax = plt.subplots(figsize=(8,6))\n",
    "        for vals in tuple(itertools.product(*tuple(x for x in tuple(params.values())[1:]))):\n",
    "            label = \" / \".join([str(x) for x in vals])\n",
    "            filters = \" & \".join([str(x)+' == \"'+str(v)+'\"' for x, v in zip(rest, vals)])\n",
    "            results.query(filters).plot(\n",
    "                x=first_key, y=scores, label=label,\n",
    "                    ax=ax, marker=\"o\", logx=LOGX);\n",
    "        plt.legend()\n",
    "        ax.set_title(scores, fontsize=18)\n",
    "\n",
    "        plt.ylim(*ylims)\n",
    "        if fileName:\n",
    "            plt.savefig(fileName)\n",
    "        plt.show()\n",
    "        return plt.gcf() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer = ModelTrainer(\n",
    "    MODEL, \n",
    "    params, \n",
    "    X_train, Y_train, X_valid, Y_valid, \n",
    "    accuracy_score,\n",
    "    thread_cnt=8\n",
    "    )\n",
    "modeltrainer.cm_setup([\"democrat\", \"republican\"])    \n",
    "modeltrainer.train()\n",
    "\n",
    "modeltrainer.save_result(\"out/mlp_params.csv\")\n",
    "cms = modeltrainer.cms\n",
    "result_MLP = modeltrainer.result\n",
    "\n",
    "bestscore, bestidx = modeltrainer.best_score(ret_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"accuracy\"\n",
    "plot_mlp(result_MLP, scores=SCORES, fileName=fname,params=params, ylims=(0.8,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"train_time\"\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\"\n",
    "fname = OUT_DIR + f\"{MODEL_TYPE}_{SCORES}.pdf\"\n",
    "plot_mlp(result_MLP, scores=SCORES, fileName=fname,params=params, ylims=(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"f1\"\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\"\n",
    "\n",
    "fname = OUT_DIR + f\"{MODEL_TYPE}_{SCORES}.pdf\"\n",
    "plot_mlp(result_MLP, scores=SCORES, fileName=fname,params=params, ylims=(0.94,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"recall\"\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\"\n",
    "\n",
    "fname = OUT_DIR + f\"{MODEL_TYPE}_{SCORES}.pdf\"\n",
    "plot_mlp(result_MLP, scores=SCORES, fileName=fname,params=params, ylims=(0.94,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"precision\"\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\"\n",
    "\n",
    "fname = OUT_DIR + f\"{MODEL_TYPE}_{SCORES}.pdf\"\n",
    "plot_mlp(result_MLP, scores=SCORES, fileName=fname,params=params, ylims=(0.94,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cms[0][1], [\"democrat\", \"republican\"], normalize=True, title=\"Confusion matrix\", cmap=plt.cm.Reds)\n",
    "plt.savefig(OUT_DIR + \"CM_\" + MODEL_TYPE + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_MLP[result_MLP[\"score\"] == np.max(result_MLP[\"score\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestscore, bestidx"
   ]
  },
  {
   "source": [
    "# KNN Classifierer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = KNN\n",
    "MODEL_TYPE = \"KNN\"\n",
    "params = {\n",
    "    \"n_neighbors\" : list(range(1, 50)), \n",
    "    \"weights\" : [\"uniform\", \"distance\"],\n",
    "    #\"algorithm\" : [\"auto\"]\n",
    "    \"algorithm\" : [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "    }\n",
    "\n",
    "SCORES = \"accuracy\"\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\"\n",
    "\n",
    "fname = OUT_DIR + f\"{MODEL_TYPE}_{SCORES}.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer = ModelTrainer(\n",
    "    MODEL, \n",
    "    params, \n",
    "    X_train, Y_train, X_valid, Y_valid, \n",
    "    accuracy_score,\n",
    "    thread_cnt=8\n",
    "    )\n",
    "modeltrainer.cm_setup([\"democrat\", \"republican\"])    \n",
    "modeltrainer.train()\n",
    "\n",
    "modeltrainer.save_result(\"out/knn_params.csv\")\n",
    "cms = modeltrainer.cms\n",
    "result_KNN = modeltrainer.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"accuracy\"\n",
    "plot_params(result_KNN, scores=SCORES, fileName=fname,params=params, ylims=(0.8,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"train_time\"\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\"\n",
    "\n",
    "fname = OUT_DIR + f\"{MODEL_TYPE}_{SCORES}.pdf\"\n",
    "plot_params(result_KNN, scores=SCORES, fileName=fname,params=params, ylims=(0,0.02));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"recall\"\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\"\n",
    "\n",
    "fname = OUT_DIR + f\"{MODEL_TYPE}_{SCORES}.pdf\"\n",
    "plot_params(result_KNN, scores=SCORES, fileName=fname,params=params, ylims=(0.8,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"precision\"\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\"\n",
    "\n",
    "fname = OUT_DIR + f\"{MODEL_TYPE}_{SCORES}.pdf\"\n",
    "plot_params(result_KNN, scores=SCORES, fileName=fname,params=params, ylims=(0.8,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"f1\"\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\"\n",
    "\n",
    "fname = OUT_DIR + f\"{MODEL_TYPE}_{SCORES}.pdf\"\n",
    "plot_params(result_KNN, scores=SCORES, fileName=fname,params=params, ylims=(0.8,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cms[0][1], [\"democrat\", \"republican\"], normalize=True, title=\"Confusion matrix\", cmap=plt.cm.Reds)\n",
    "plt.savefig(OUT_DIR + \"CM_\" + MODEL_TYPE + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_KNN[result_KNN[\"score\"] == np.max(result_KNN[\"score\"])]"
   ]
  },
  {
   "source": [
    "# RandomForrest classifierer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = RFC\n",
    "MODEL_TYPE = \"RFC\"\n",
    "params = {\n",
    "    \"n_estimators\": [1, 8, 10, 12, 15, 20, 50, 100,  1000],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "SCORES = \"accuracy\"\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\"\n",
    "\n",
    "fname = OUT_DIR + f\"{MODEL_TYPE}_{SCORES}.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer = ModelTrainer(\n",
    "    MODEL, \n",
    "    params, \n",
    "    X_train, Y_train, X_valid, Y_valid, \n",
    "    accuracy_score,\n",
    "    thread_cnt=8\n",
    "    )\n",
    "modeltrainer.cm_setup([\"democrat\", \"republican\"])    \n",
    "modeltrainer.train()\n",
    "\n",
    "modeltrainer.save_result(\"out/rf_params.csv\")\n",
    "cms = modeltrainer.cms\n",
    "result_RFC = modeltrainer.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_RFC = pd.read_csv(\"out/rf_params.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"accuracy\"\n",
    "plot_params(result_RFC, scores=SCORES, fileName=fname,params=params, ylims=(0.8,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"train_time\"\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\"\n",
    "\n",
    "fname = OUT_DIR + f\"{MODEL_TYPE}_{SCORES}.pdf\"\n",
    "plot_params(result_RFC, scores=SCORES, fileName=fname,params=params, ylims=(0,2.5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"f1\"\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\"\n",
    "\n",
    "fname = OUT_DIR + f\"{MODEL_TYPE}_{SCORES}.pdf\"\n",
    "plot_params(result_RFC, scores=SCORES, fileName=fname,params=params, ylims=(0.8,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"recall\"\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\"\n",
    "\n",
    "fname = OUT_DIR + f\"{MODEL_TYPE}_{SCORES}.pdf\"\n",
    "plot_params(result_RFC, scores=SCORES, fileName=fname,params=params, ylims=(0,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"precision\"\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\"\n",
    "\n",
    "fname = OUT_DIR + f\"{MODEL_TYPE}_{SCORES}.pdf\"\n",
    "plot_params(result_RFC, scores=SCORES, fileName=fname,params=params, ylims=(0,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cms[0][1], [\"democrat\", \"republican\"], normalize=True, title=\"Confusion matrix\", cmap=plt.cm.Reds)\n",
    "plt.savefig(OUT_DIR + \"CM_\" + MODEL_TYPE + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_RFC[result_RFC[\"score\"] == np.max(result_RFC[\"score\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filepreparation for the Kagglecompetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(datapath_test).drop(\"ID\",axis = 1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.replace(\"n\",-1)\n",
    "df_test = df_test.replace(\"y\",1)\n",
    "df_test = df_test.replace(\"unknown\",0)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  \n",
    "scaler.fit(df_test) \n",
    "df_test_SC = scaler.transform(df_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RFC(n_estimators = 2, max_features = 'sqrt', criterion =  'entropy')\n",
    "clf.fit(X_lrn,Y_lrn)\n",
    "Y_pred = clf.predict(df_test_SC)"
   ]
  },
  {
   "source": [
    "# Upload the file for Kaggle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_examp = pd.read_csv(datapath_examp)\n",
    "ID_df = df_examp[\"ID\"]\n",
    "ID_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_data = list(zip(list(ID_df), Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_pred = Y_pred.drop(\"ID\",axis = 1)\n",
    "#solution_data = list(zip(list(range(0,len(Y_pred))), Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_table = pd.DataFrame(solution_data, columns=['ID', 'Class'])\n",
    "solution_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_table.to_csv(f\"results/RFC.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bitb5f188b5fd4549769c9ea1e1a366fa0d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}