{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit ('ML_2020': pipenv)",
   "display_name": "Python 3.8.6 64-bit ('ML_2020': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "d6f8d2b41179c5e5fc034bbc40427a4395636c4d26988e51920bd3cc303b8725"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Scalars\n",
    "from sklearn.preprocessing import StandardScaler,PowerTransformer,MinMaxScaler,QuantileTransformer,normalize\n",
    "# Features\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "# required for importin modules from other directories\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "from common import misc\n",
    "from common.data_parser import *\n",
    "from common.model_trainer import *\n",
    "from common.misc import *\n",
    "from config import *\n",
    "from heart_helpers import *\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "MODEL = KNN\n",
    "params = {\n",
    "    \"n_neighbors\" : list(range(3,50)), \n",
    "    \"weights\" : [\"uniform\", \"distance\"],\n",
    "    \"p\" : [1,2]\n",
    "    }\n",
    "TEST_SIZE = 0.25\n",
    "RND_STATE = 42"
   ]
  },
  {
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(preprocessed_data, labels, test_size=0.3, random_state=1 )\n",
    "\n",
    "hidden_layers = []\n",
    "for i in range(5,10):\n",
    "    for j in range(5,10):\n",
    "        hidden_layers.append((i,j))\n",
    "print(hidden_layers)\n",
    "params = {\n",
    "    \"hidden_layer_sizes\" : hidden_layers, \n",
    "    \"alpha\" : [0.001, 0.0001],\n",
    "    #solver\" : [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "    }"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = parse_heart_disease(\"big\")\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_params(results, scores=\"score\",fileName=None):\n",
    "    gini = results.loc[(results['criterion'] == \"gini\")]\n",
    "    entropy = results.loc[(results['criterion'] == \"entropy\")]\n",
    "\n",
    "    plt.style.use('seaborn')\n",
    "    if isinstance(scores, str):\n",
    "        fix, ax = plt.subplots(figsize=(8,6))\n",
    "        for f in params[\"max_features\"]:\n",
    "            for s in [2, 8]:\n",
    "                entropy[entropy[\"max_features\"]==f].plot(x=\"n_estimators\", y=SCORE, label=f\"gini + {f} + {s}\",\n",
    "                    ax=ax, marker=\"o\", logx=True);\n",
    "                gini[gini[\"max_features\"]==f].plot(x=\"n_estimators\", y=SCORE, label=f\"gini + {f} + {s}\", \n",
    "                    ax=ax, marker=\"o\", logx=True);\n",
    "        plt.legend()\n",
    "        ax.set_title(scores, fontsize=18)\n",
    "        plt.ylim(0, 1.)\n",
    "        plt.show()\n",
    "        if fileName:\n",
    "            plt.savefig(fileName)\n",
    "        return plt.gcf()\n",
    "\n",
    "    if isinstance(scores, list):\n",
    "        fix, ax = plt.subplots(nrows=len(scores),figsize=(8,6*len(scores)))\n",
    "        for score in scores:\n",
    "            for f in params[\"max_features\"]:\n",
    "                for s in [2, 8]:\n",
    "                    entropy[entropy[\"max_features\"]==f].plot(x=\"n_estimators\", y=score, label=f\"gini + {f} + {s}\",\n",
    "                        ax=ax, marker=\"o\", logx=True);\n",
    "                    gini[gini[\"max_features\"]==f].plot(x=\"n_estimators\", y=score, label=f\"gini + {f} + {s}\", \n",
    "                        ax=ax, marker=\"o\", logx=True);\n",
    "            plt.legend()\n",
    "            ax.set_title(score, fontsize=18)\n",
    "        plt.ylim(0, 1.)\n",
    "        plt.show()\n",
    "        if fileName:\n",
    "            plt.savefig(fileName)\n",
    "        return plt.gcf()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "source": [
    "# Impute mode = 0"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_mode = 0\n",
    "\n",
    "df = process_heart(df_raw, impute_mode=impute_mode)\n",
    "x, y = df[HEART_FEATS], df[HEART_TARGET]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=TEST_SIZE, random_state=RND_STATE)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer = ModelTrainer(\n",
    "    MODEL, \n",
    "    params, \n",
    "    x_train, y_train, x_test, y_test, \n",
    "    accuracy_score,\n",
    "    thread_cnt=4\n",
    "    )\n",
    "\n",
    "modeltrainer.train()\n",
    "#modeltrainer.save_result(\"out/knn_params.csv\")\n",
    "result = modeltrainer.result\n",
    "result.head()\n",
    "\n",
    "SCORES = \"score\"\n",
    "plot_params(result, scores=SCORES)\n"
   ]
  },
  {
   "source": [
    "# Impute mode = 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_mode = 0\n",
    "\n",
    "df = process_heart(df_raw, impute_mode=impute_mode)\n",
    "x, y = df[HEART_FEATS], df[HEART_TARGET]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=TEST_SIZE, random_state=RND_STATE)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer = ModelTrainer(\n",
    "    MODEL, \n",
    "    params, \n",
    "    x_train, y_train, x_test, y_test, \n",
    "    accuracy_score,\n",
    "    thread_cnt=8\n",
    "    )\n",
    "\n",
    "modeltrainer.train()\n",
    "#modeltrainer.save_result(\"out/knn_params.csv\")\n",
    "result = modeltrainer.result\n",
    "result.head()\n",
    "\n",
    "SCORES = \"score\"\n",
    "plot_params(result, scores=SCORES)"
   ]
  },
  {
   "source": [
    "# Impute mode = 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_mode = 0\n",
    "\n",
    "df = process_heart(df_raw, impute_mode=impute_mode)\n",
    "x, y = df[HEART_FEATS], df[HEART_TARGET]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=TEST_SIZE, random_state=RND_STATE)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer = ModelTrainer(\n",
    "    MODEL, \n",
    "    params, \n",
    "    x_train, y_train, x_test, y_test, \n",
    "    accuracy_score,\n",
    "    thread_cnt=8\n",
    "    )\n",
    "\n",
    "modeltrainer.train()\n",
    "#modeltrainer.save_result(\"out/knn_params.csv\")\n",
    "result = modeltrainer.result\n",
    "result.head()\n",
    "\n",
    "SCORES = \"score\"\n",
    "plot_params(result, scores=SCORES)"
   ]
  },
  {
   "source": [
    "# Confusion matrices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer = ModelTrainer(MODEL, params, x_train, y_train, x_test, y_test, accuracy_score, thread_cnt=4)\n",
    "modeltrainer.cm_setup([0, 1, 2, 3, 4])\n",
    "modeltrainer.train()\n",
    "modeltrainer.save_result(\"out/rf.csv\")\n",
    "\n",
    "cms = modeltrainer.cms\n",
    "\n",
    "df_results = modeltrainer.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer.plot_confusion_matrix(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cms[0][1], [0, 1, 2, 3, 4], normalize=True, title=\"Confusion matrix\", cmap=plt.cm.Reds)"
   ]
  }
 ]
}