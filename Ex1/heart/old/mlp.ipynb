{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('ML_2020': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "d6f8d2b41179c5e5fc034bbc40427a4395636c4d26988e51920bd3cc303b8725"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import itertools\n",
    "import pathlib\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Scalars\n",
    "from sklearn.preprocessing import StandardScaler,PowerTransformer,MinMaxScaler,QuantileTransformer,normalize\n",
    "# Features\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "\n",
    "# required for importin modules from other directories\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "from common import misc\n",
    "from common.data_parser import *\n",
    "from common.model_trainer import *\n",
    "from common.misc import *\n",
    "from config import *\n",
    "from heart_helpers import *\n",
    "\n",
    "plt.style.use(\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = MLP\n",
    "MODEL_TYPE = \"MLP\"\n",
    "hidden_layers = []\n",
    "for i in range(5,10):\n",
    "    for j in range(5,10):\n",
    "        hidden_layers.append((i,j))\n",
    "print(\"hidden_layers:\")\n",
    "print(hidden_layers)\n",
    "params = {\n",
    "    \"hidden_layer_sizes\" : hidden_layers, \n",
    "    \"alpha\" : [0.001, 0.0001],\n",
    "    #solver\" : [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "    }\n",
    "TEST_SIZE = 0.25\n",
    "RND_STATE = 42\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\"\n",
    "\n",
    "SET = \"binary\" # multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SET==\"binary\":\n",
    "    df_raw = parse_heart_disease(\"sma\")\n",
    "else:\n",
    "    df_raw = parse_heart_disease(\"big\")\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGX = False\n",
    "YLIMS = (0.5, 1) if SET==\"binary\" else (0.4, 0.8)\n",
    "\n",
    "def plot_params(results, scores=\"score\", fileName=None, params=params, ylims=YLIMS):\n",
    "    param_keys = list(params)\n",
    "    first_key = param_keys[0]\n",
    "    rest = param_keys[1:]\n",
    "\n",
    "    plt.style.use('seaborn')\n",
    "    if isinstance(scores, str):\n",
    "        fix, ax = plt.subplots(figsize=(8,6))\n",
    "        for vals in tuple(itertools.product(*tuple(x for x in tuple(params.values())[1:]))):\n",
    "            label = \" / \".join([str(x) for x in vals])\n",
    "            filters = \" & \".join([str(x)+' == \"'+str(v)+'\"' for x, v in zip(rest, vals)])\n",
    "            results.query(filters).plot(\n",
    "                x=first_key, y=scores, label=label,\n",
    "                    ax=ax, marker=\"o\", logx=LOGX);\n",
    "        plt.legend()\n",
    "        ax.set_title(scores, fontsize=18)\n",
    "\n",
    "        plt.ylim(*YLIMS)\n",
    "        if fileName:\n",
    "            plt.savefig(fileName)\n",
    "        plt.show()\n",
    "        return plt.gcf() "
   ]
  },
  {
   "source": [
    "# Impute mode = 0"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = None #StandardScaler() # None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_mode = 0\n",
    "fname = OUT_DIR + f\"{SET}_{MODEL_TYPE}_{impute_mode}.pdf\" if not scaler else OUT_DIR + f\"{SET}_{MODEL_TYPE}_{impute_mode}_scaler.pdf\"\n",
    "\n",
    "\n",
    "df = process_heart(df_raw, impute_mode=impute_mode, scaler=scaler)\n",
    "x, y = df[HEART_FEATS], df[HEART_TARGET]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=TEST_SIZE, random_state=RND_STATE)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer = ModelTrainer(\n",
    "    MODEL, \n",
    "    params, \n",
    "    x_train, y_train, x_test, y_test, \n",
    "    accuracy_score,\n",
    "    thread_cnt=8\n",
    "    )\n",
    "\n",
    "modeltrainer.train()\n",
    "#modeltrainer.save_result(\"out/knn_params.csv\")\n",
    "result = modeltrainer.result\n",
    "result.head()\n",
    "\n",
    "SCORES = \"accuracy\"\n",
    "plot_params(result, scores=SCORES, fileName=fname);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"accuracy\"\n",
    "plot_params(result, scores=SCORES);"
   ]
  },
  {
   "source": [
    "# Impute mode = 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_mode = 1\n",
    "fname = OUT_DIR + f\"{SET}_{MODEL_TYPE}_{impute_mode}.pdf\" if not scaler else OUT_DIR + f\"{SET}_{MODEL_TYPE}_{impute_mode}_scaler.pdf\"\n",
    "\n",
    "df = process_heart(df_raw, impute_mode=impute_mode, scaler=scaler)\n",
    "x, y = df[HEART_FEATS], df[HEART_TARGET]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=TEST_SIZE, random_state=RND_STATE)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer = ModelTrainer(\n",
    "    MODEL, \n",
    "    params, \n",
    "    x_train, y_train, x_test, y_test, \n",
    "    accuracy_score,\n",
    "    thread_cnt=8\n",
    "    )\n",
    "\n",
    "modeltrainer.train()\n",
    "#modeltrainer.save_result(\"out/knn_params.csv\")\n",
    "result = modeltrainer.result\n",
    "result.head()\n",
    "\n",
    "SCORES = \"accuracy\"\n",
    "plot_params(result, scores=SCORES, fileName=fname);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"accuracy\"\n",
    "plot_params(result, scores=SCORES);"
   ]
  },
  {
   "source": [
    "# Impute mode = 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_mode = 2\n",
    "fname = OUT_DIR + f\"{SET}_{MODEL_TYPE}_{impute_mode}.pdf\" if not scaler else OUT_DIR + f\"{SET}_{MODEL_TYPE}_{impute_mode}_scaler.pdf\"\n",
    "\n",
    "df = process_heart(df_raw, impute_mode=impute_mode, scaler=scaler)\n",
    "x, y = df[HEART_FEATS], df[HEART_TARGET]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=TEST_SIZE, random_state=RND_STATE)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer = ModelTrainer(\n",
    "    MODEL, \n",
    "    params, \n",
    "    x_train, y_train, x_test, y_test, \n",
    "    accuracy_score,\n",
    "    thread_cnt=8\n",
    "    )\n",
    "\n",
    "modeltrainer.train()\n",
    "#modeltrainer.save_result(\"out/knn_params.csv\")\n",
    "result = modeltrainer.result\n",
    "result.head()\n",
    "\n",
    "SCORES = \"accuracy\"\n",
    "plot_params(result, scores=SCORES, fileName=fname);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = \"accuracy\"\n",
    "plot_params(result, scores=SCORES);"
   ]
  },
  {
   "source": [
    "# Confusion matrices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer = ModelTrainer(MODEL, params, x_train, y_train, x_test, y_test, accuracy_score, thread_cnt=4)\n",
    "modeltrainer.cm_setup([0, 1, 2, 3, 4])\n",
    "modeltrainer.train()\n",
    "modeltrainer.save_result(\"out/rf.csv\")\n",
    "\n",
    "cms = modeltrainer.cms\n",
    "\n",
    "df_results = modeltrainer.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer.plot_confusion_matrix(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cms[0][1], [0, 1, 2, 3, 4], normalize=True, title=\"Confusion matrix\", cmap=plt.cm.Reds)"
   ]
  }
 ]
}