{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('ML_2020': venv)",
   "metadata": {
    "interpreter": {
     "hash": "d6f8d2b41179c5e5fc034bbc40427a4395636c4d26988e51920bd3cc303b8725"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import itertools\n",
    "import pathlib\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Scalars\n",
    "from sklearn.preprocessing import StandardScaler,PowerTransformer,MinMaxScaler,QuantileTransformer,normalize\n",
    "# Features\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "\n",
    "# required for importin modules from other directories\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "from common import misc\n",
    "from common.data_parser import *\n",
    "from common.model_trainer import *\n",
    "from common.misc import *\n",
    "from config import *\n",
    "from heart_helpers import *\n",
    "\n",
    "# NEW --> contains plot_params, plot_confusion_matrix and plot_corr_heatmap\n",
    "from common.plotting import *\n",
    "\n",
    "plt.style.use(\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter setup for this notebook\n",
    "MODEL = MLP\n",
    "MODEL_TYPE = \"MLP\"\n",
    "hidden_layers = []\n",
    "for i in range(5,10):\n",
    "    for j in range(5,10):\n",
    "        hidden_layers.append((i,j))\n",
    "print(\"hidden_layers:\")\n",
    "print(hidden_layers)\n",
    "params = {\n",
    "    \"hidden_layer_sizes\" : hidden_layers, \n",
    "    \"alpha\" : [0.001, 0.0001],\n",
    "    #solver\" : [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "    }\n",
    "TEST_SIZE = 0.25\n",
    "RND_STATE = 42\n",
    "OUT_DIR = f\"out/{MODEL_TYPE}/\"\n",
    "SET = \"multi\" # \"multi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_out_dirs():\n",
    "    import os\n",
    "    if not os.path.exists(\"./out\"):\n",
    "        os.makedirs(\"./out\")\n",
    "    if not os.path.exists(\"./out/runtimes\"):\n",
    "        os.makedirs(\"./out/runtimes\")\n",
    "\n",
    "    for md in [\"RFC\", \"KNN\", \"MLP\"]:\n",
    "        if not os.path.exists(f\"./out/{md}\"):\n",
    "            os.makedirs(f\"./out/{md}\")\n",
    "        if not os.path.exists(f\"./out/{md}/cms\"):\n",
    "            os.makedirs(f\"./out/{md}/cms\")\n",
    "        if not os.path.exists(f\"./out/{md}/params\"):\n",
    "            os.makedirs(f\"./out/{md}/params\")\n",
    "create_out_dirs()\n",
    "\n",
    "# Filename function\n",
    "def get_fname(save_cm=False,force_filename:str=None, file_format:str=\"pdf\"):\n",
    "    \"\"\"Calculate filename based on parameter and variable values\n",
    "    OR\n",
    "    force a filenamme by appending it to the OUT_DIR set above\n",
    "    \"\"\"\n",
    "    if force_filename:\n",
    "        return OUT_DIR + force_filename\n",
    "    if save_cm:\n",
    "        return OUT_DIR + \"cms/\" + f\"{SET}_{MODEL_TYPE}_{impute_mode}_{BW}_CM.pdf\" if not scaler else OUT_DIR + \"cms/\" + f\"{SET}_{MODEL_TYPE}_{impute_mode}_{BW}_CM_scaler.pdf\"\n",
    "    return OUT_DIR + f\"{SET}_{MODEL_TYPE}_{impute_mode}_{SCORES}.pdf\" if not scaler else OUT_DIR + f\"{SET}_{MODEL_TYPE}_{impute_mode}_{SCORES}_scaler.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SET==\"binary\":\n",
    "    df_raw = parse_heart_disease(\"sma\")\n",
    "    SET_CLASSES = [0, 1]\n",
    "else:\n",
    "    df_raw = parse_heart_disease(\"big\")\n",
    "    SET_CLASSES = [0, 1, 2, 3, 4]\n",
    "\n",
    "df_raw.info()"
   ]
  },
  {
   "source": [
    "# FIRST TEST"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup test specific parameters/variables here\n",
    "scaler = StandardScaler() # None\n",
    "SCALER_NAME = \"standard\"\n",
    "impute_mode = 0\n",
    "\n",
    "# Or also modeltrainer parameters\n",
    "eval_func = accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y  = process_heart(df_raw, impute_mode = impute_mode, scaler=scaler, ret_xy=True)\n",
    "# OR\n",
    "#df = process_heart(df_raw, , impute_mode = impute_mode, scaler=scaler, ret_xy=False)\n",
    "#display(df.info())\n",
    "#x, y = df[VOTING_FEATS], df[VOTING_TARGET]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=TEST_SIZE, random_state=RND_STATE)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate modeltrainer and train models\n",
    "modeltrainer = ModelTrainer(\n",
    "    MODEL, \n",
    "    params, \n",
    "    x_train, y_train, x_test, y_test, \n",
    "    eval_func,\n",
    "    thread_cnt=4\n",
    "    )\n",
    "# Setup cm config if wanted\n",
    "# modeltrainer.cm_setup([0, 1])\n",
    "# or\n",
    "modeltrainer.cm_setup(SET_CLASSES)\n",
    "modeltrainer.train()\n",
    "\n",
    "#modeltrainer.save_result(\"out/knn_params.csv\")\n",
    "result = modeltrainer.result\n",
    "result.head()\n",
    "\n",
    "SCORES = \"accuracy\"\n",
    "# if fileName is set, make sure that the directory exists\n",
    "plot_params(result, params=params,scores=SCORES, ylims=(0.4,1.1));"
   ]
  },
  {
   "source": [
    "# TESTS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # None\n",
    "SCALER_NAME = \"standard\""
   ]
  },
  {
   "source": [
    "# IMPUTE Mode = 0"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_mode = 0\n",
    "\n",
    "# Or also modeltrainer parameters\n",
    "eval_func = accuracy_score\n",
    "\n",
    "# Prepare data and do split\n",
    "x, y  = process_heart(df_raw, impute_mode = impute_mode, scaler=scaler, ret_xy=True)\n",
    "# OR\n",
    "#df = process_heart(df_raw, , impute_mode = impute_mode, scaler=scaler, ret_xy=False)\n",
    "#display(df.info())\n",
    "#x, y = df[VOTING_FEATS], df[VOTING_TARGET]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=TEST_SIZE, random_state=RND_STATE)\n",
    "y\n",
    "\n",
    "# Instantiate modeltrainer and train models\n",
    "modeltrainer = ModelTrainer(\n",
    "    MODEL, \n",
    "    params, \n",
    "    x_train, y_train, x_test, y_test, \n",
    "    eval_func,\n",
    "    thread_cnt=4\n",
    "    )\n",
    "# Setup cm config if wanted\n",
    "# modeltrainer.cm_setup([0, 1])\n",
    "# or\n",
    "modeltrainer.cm_setup(SET_CLASSES)\n",
    "modeltrainer.train()\n",
    "\n",
    "#modeltrainer.save_result(\"out/knn_params.csv\")\n",
    "result = modeltrainer.result\n",
    "result.head()\n",
    "\n",
    "SCORES = \"accuracy\"\n",
    "plot_params(result, params=params,scores=SCORES, fileName=get_fname(), ylims=(0.4,1.1));\n",
    "SCORES = \"f1\"\n",
    "plot_params(result, params=params,scores=SCORES, fileName=get_fname(), ylims=(0.4,1.1));\n",
    "SCORES = \"recall\"\n",
    "plot_params(result, params=params,scores=SCORES, fileName=get_fname(), ylims=(0.4,1.1));\n",
    "SCORES = \"precision\"\n",
    "plot_params(result, params=params,scores=SCORES, fileName=get_fname(), ylims=(0.4,1.1));\n",
    "\n",
    "\n",
    "bestscore, bestidx = modeltrainer.best_score(ret_index=True)\n",
    "worstscore, worstidx = modeltrainer.worst_score(ret_index=True)\n",
    "print(\"Best params\")\n",
    "plt.clf()\n",
    "modeltrainer.plot_confusion_matrix(bestidx, title=f\"Confusion matrix\\n(acc={bestscore})\");\n",
    "BW = \"best\" # for naming of plot output file\n",
    "plt.savefig(get_fname(save_cm=True))\n",
    "print(\"Worst params\")\n",
    "plt.clf()\n",
    "BW = \"worst\" # for naming of plot output file\n",
    "modeltrainer.plot_confusion_matrix(worstidx, title=f\"Confusion matrix\\n(acc={worstscore})\");\n",
    "plt.savefig(get_fname(save_cm=True))"
   ]
  },
  {
   "source": [
    "# IMPUTE Mode = 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_mode = 1\n",
    "\n",
    "# Or also modeltrainer parameters\n",
    "eval_func = accuracy_score\n",
    "\n",
    "# Prepare data and do split\n",
    "x, y  = process_heart(df_raw, impute_mode = impute_mode, scaler=scaler, ret_xy=True)\n",
    "# OR\n",
    "#df = process_heart(df_raw, , impute_mode = impute_mode, scaler=scaler, ret_xy=False)\n",
    "#display(df.info())\n",
    "#x, y = df[VOTING_FEATS], df[VOTING_TARGET]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=TEST_SIZE, random_state=RND_STATE)\n",
    "y\n",
    "\n",
    "# Instantiate modeltrainer and train models\n",
    "modeltrainer = ModelTrainer(\n",
    "    MODEL, \n",
    "    params, \n",
    "    x_train, y_train, x_test, y_test, \n",
    "    eval_func,\n",
    "    thread_cnt=4\n",
    "    )\n",
    "# Setup cm config if wanted\n",
    "# modeltrainer.cm_setup([0, 1])\n",
    "# or\n",
    "modeltrainer.cm_setup(SET_CLASSES)\n",
    "modeltrainer.train()\n",
    "\n",
    "#modeltrainer.save_result(\"out/knn_params.csv\")\n",
    "result = modeltrainer.result\n",
    "result.head()\n",
    "\n",
    "SCORES = \"accuracy\"\n",
    "plot_params(result, params=params,scores=SCORES, fileName=get_fname(), ylims=(0.4,1.1));\n",
    "SCORES = \"f1\"\n",
    "plot_params(result, params=params,scores=SCORES, fileName=get_fname(), ylims=(0.4,1.1));\n",
    "SCORES = \"recall\"\n",
    "plot_params(result, params=params,scores=SCORES, fileName=get_fname(), ylims=(0.4,1.1));\n",
    "SCORES = \"precision\"\n",
    "plot_params(result, params=params,scores=SCORES, fileName=get_fname(), ylims=(0.4,1.1));\n",
    "\n",
    "\n",
    "bestscore, bestidx = modeltrainer.best_score(ret_index=True)\n",
    "worstscore, worstidx = modeltrainer.worst_score(ret_index=True)\n",
    "print(\"Best params\")\n",
    "plt.clf()\n",
    "modeltrainer.plot_confusion_matrix(bestidx, title=f\"Confusion matrix\\n(acc={bestscore})\");\n",
    "BW = \"best\" # for naming of plot output file\n",
    "plt.savefig(get_fname(save_cm=True))\n",
    "print(\"Worst params\")\n",
    "plt.clf()\n",
    "BW = \"worst\" # for naming of plot output file\n",
    "modeltrainer.plot_confusion_matrix(worstidx, title=f\"Confusion matrix\\n(acc={worstscore})\");\n",
    "plt.savefig(get_fname(save_cm=True))"
   ]
  },
  {
   "source": [
    "# IMPUTE Mode = 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_mode = 2\n",
    "\n",
    "# Or also modeltrainer parameters\n",
    "eval_func = accuracy_score\n",
    "\n",
    "# Prepare data and do split\n",
    "x, y  = process_heart(df_raw, impute_mode = impute_mode, scaler=scaler, ret_xy=True)\n",
    "# OR\n",
    "#df = process_heart(df_raw, , impute_mode = impute_mode, scaler=scaler, ret_xy=False)\n",
    "#display(df.info())\n",
    "#x, y = df[VOTING_FEATS], df[VOTING_TARGET]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=TEST_SIZE, random_state=RND_STATE)\n",
    "y\n",
    "\n",
    "# Instantiate modeltrainer and train models\n",
    "modeltrainer = ModelTrainer(\n",
    "    MODEL, \n",
    "    params, \n",
    "    x_train, y_train, x_test, y_test, \n",
    "    eval_func,\n",
    "    thread_cnt=4\n",
    "    )\n",
    "# Setup cm config if wanted\n",
    "# modeltrainer.cm_setup([0, 1])\n",
    "# or\n",
    "modeltrainer.cm_setup(SET_CLASSES)\n",
    "modeltrainer.train()\n",
    "\n",
    "#modeltrainer.save_result(\"out/knn_params.csv\")\n",
    "result = modeltrainer.result\n",
    "result.head()\n",
    "\n",
    "SCORES = \"accuracy\"\n",
    "plot_params(result, params=params,scores=SCORES, fileName=get_fname(), ylims=(0.4,1.1));\n",
    "SCORES = \"f1\"\n",
    "plot_params(result, params=params,scores=SCORES, fileName=get_fname(), ylims=(0.4,1.1));\n",
    "SCORES = \"recall\"\n",
    "plot_params(result, params=params,scores=SCORES, fileName=get_fname(), ylims=(0.4,1.1));\n",
    "SCORES = \"precision\"\n",
    "plot_params(result, params=params,scores=SCORES, fileName=get_fname(), ylims=(0.4,1.1));\n",
    "\n",
    "\n",
    "bestscore, bestidx = modeltrainer.best_score(ret_index=True)\n",
    "worstscore, worstidx = modeltrainer.worst_score(ret_index=True)\n",
    "print(\"Best params\")\n",
    "plt.clf()\n",
    "modeltrainer.plot_confusion_matrix(bestidx, title=f\"Confusion matrix\\n(acc={bestscore})\");\n",
    "BW = \"best\" # for naming of plot output file\n",
    "plt.savefig(get_fname(save_cm=True))\n",
    "print(\"Worst params\")\n",
    "plt.clf()\n",
    "BW = \"worst\" # for naming of plot output file\n",
    "modeltrainer.plot_confusion_matrix(worstidx, title=f\"Confusion matrix\\n(acc={worstscore})\");\n",
    "plt.savefig(get_fname(save_cm=True))"
   ]
  }
 ]
}