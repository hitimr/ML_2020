{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('ML_2020': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "d6f8d2b41179c5e5fc034bbc40427a4395636c4d26988e51920bd3cc303b8725"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import time\n",
    "import pathlib\n",
    "from math import sqrt\n",
    "from math import log2\n",
    "# packgaes\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# packages\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "## sklearn\n",
    "from sklearn.preprocessing import StandardScaler,PowerTransformer,MinMaxScaler,QuantileTransformer,normalize\n",
    "from sklearn.model_selection import train_test_split, learning_curve, ShuffleSplit\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_poisson_deviance\n",
    "from sklearn.metrics import mean_gamma_deviance\n",
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# for selection the right path\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "from common.DataParser import parse_superconductivity\n",
    "from common.model_trainer_reg import *\n",
    "from common.regression_plotfunctions import *\n",
    "\n",
    "from GD.LinearRegression import LinearRegression\n",
    "from KNN.KNNRegressor import KNNRegressor\n",
    "\n",
    "import supercon_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = parse_superconductivity()\n",
    "\n",
    "#df_raw = df_raw.sample(3000)\n",
    "df_raw"
   ]
  },
  {
   "source": [
    "# Train and Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = supercon_preprocessing.preprocessing(df_raw, transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "test_size = 0.3"
   ]
  },
  {
   "source": [
    "## SGD-Regression\n",
    "\n",
    "### sklearn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = SGDRegressor\n",
    "NAME = \"SGD\"\n",
    "PATH = \"out/\"+NAME+\"/\"\n",
    "params = {\"alpha\" : [0.0001, 0.001, 0.01]}\n",
    "\n",
    "\n",
    "modeltrainer = ModelTrainer(MODEL, params, X, Y, thread_cnt=4)\n",
    "########### train with TrainTestSplit  ###################\n",
    "modeltrainer.TTSplit(test_size = test_size)\n",
    "modeltrainer.train()\n",
    "results = modeltrainer.retResults(PATH + \"sklearn_TTS_SGD.csv\")\n",
    "display(results)\n",
    "############ shuffle_Cross validation  ###################\n",
    "modeltrainer.CV_shuffle_split(k = n_splits, test_size = test_size, random_state = 42)\n",
    "results = modeltrainer.retResults(PATH + \"sklearn_CV_SGD.csv\")\n",
    "display(results)"
   ]
  },
  {
   "source": [
    "#### My SGD-Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = LinearRegression\n",
    "params = {\"alpha\" : [0.0001, 0.005], \"max_iter\": [1000]}\n",
    "\n",
    "modeltrainer = ModelTrainer(MODEL, params, X, Y, thread_cnt=1)\n",
    "########### train with TrainTestSplit  ###################\n",
    "modeltrainer.TTSplit(test_size = test_size)\n",
    "modeltrainer.train()\n",
    "results = modeltrainer.retResults(PATH + \"my_TTS_SGD.csv\")\n",
    "display(results)\n",
    "############ shuffle_Cross validation  ###################\n",
    "modeltrainer.CV_shuffle_split(k = n_splits, test_size = test_size, random_state = 42)\n",
    "results = modeltrainer.retResults(PATH + \"my_CV_SGD.csv\")\n",
    "display(results)"
   ]
  },
  {
   "source": [
    "## KNN-Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = KNeighborsRegressor\n",
    "params = {\n",
    "    \"n_neighbors\" : [5, 10],\n",
    "    \"p\": [1, 2],\n",
    "    \"weights\" : [\"uniform\"],\n",
    "    \"algorithm\": [\"brute\", \"kd_tree\", \"ball_tree\"]\n",
    "}\n",
    "NAME = \"KNN\"\n",
    "PATH = \"out/\"+NAME+\"/\"\n",
    "\n",
    "modeltrainer = ModelTrainer(MODEL, params, X, Y, thread_cnt=4)\n",
    "############ shuffle_Cross validation  ###################\n",
    "modeltrainer.CV_shuffle_split(k = n_splits, test_size = test_size, random_state = 42)\n",
    "liste = modeltrainer.get_result_list()\n",
    "results = modeltrainer.retResults(PATH + \"sklearn_CV_KNN.csv\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = KNNRegressor\n",
    "params = {\"n_neighbors\" : [5, 10],\n",
    "           \"p\": [1, 2],\n",
    "           \"chunk_size\": [1, 4]}\n",
    "NAME = \"KNN\"\n",
    "PATH = \"out/\"+NAME+\"/\"\n",
    "\n",
    "modeltrainer = ModelTrainer(MODEL, params, X, Y, thread_cnt=4)\n",
    "########### train with TrainTestSplit  ###################\n",
    "#modeltrainer.TTSplit(test_size = test_size)\n",
    "#modeltrainer.train()\n",
    "#results = modeltrainer.retResults(PATH + \"my_TTS_KNN.csv\")\n",
    "#display(results)\n",
    "############ shuffle_Cross validation  ###################\n",
    "modeltrainer.CV_shuffle_split(k = n_splits, test_size = test_size, random_state = 42)\n",
    "results = modeltrainer.retResults(PATH + \"my_CV_KNN.csv\")\n",
    "display(results)"
   ]
  },
  {
   "source": [
    "## Data for runtime analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_size_experiment(\n",
    "        subset_size=np.arange(0.1, 1.1, 0.1),\n",
    "        path_csv=PATH+\"sklearn_TTS_KNN_app.csv\"\n",
    "        ):\n",
    "    results = []\n",
    "    k = 1\n",
    "    break_next = False\n",
    "    for subs in subset_size:\n",
    "        if subs < 1:\n",
    "            n_train = int(subs * len(Y))\n",
    "            print(f\"{100*subs:.2f}% --> n_train={n_train}\")\n",
    "        else:\n",
    "            n_train = subs\n",
    "            print(f\"{100*subs/len(Y):.2f}% --> n_train={n_train}\")\n",
    "        if break_next:\n",
    "            break\n",
    "        if n_train > len(Y):\n",
    "            n_train = len(Y)\n",
    "            break_next = True\n",
    "        modeltrainer = ModelTrainer(MODEL, params, X[:n_train,:], Y[:n_train], thread_cnt=thread_cnt)\n",
    "        modeltrainer.TTSplit(test_size = test_size)\n",
    "        modeltrainer.k = k \n",
    "        modeltrainer.train()\n",
    "        #print(modeltrainer.results)\n",
    "        results.append(modeltrainer.results)\n",
    "        k += 1\n",
    "        print(\"-\"*30)\n",
    "    results = pd.concat(results, ignore_index=True)\n",
    "    results.to_csv(path_csv, index=False)\n",
    "    display(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = KNeighborsRegressor\n",
    "params = {\n",
    "    \"weights\" : [\"uniform\"],\n",
    "    \"algorithm\": [\"brute\", \"kd_tree\", \"ball_tree\"]\n",
    "}\n",
    "NAME = \"KNN\"\n",
    "PATH = \"out/runtimes/\"\n",
    "########### train with TrainTestSplit  ###################\n",
    "thread_cnt = 4\n",
    "results = dataset_size_experiment([20, 200, 400, 800, 1600, 3200, 6400, 12800, 16000, 25600] ,path_csv=PATH+\"sklearn_TTS_KNN_app.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = KNNRegressor\n",
    "params = {\"n_neighbors\" : [5],\n",
    "           \"p\": [2],\n",
    "           \"chunk_size\": [1, 4]}\n",
    "NAME = \"KNN\"\n",
    "PATH = \"out/runtimes/\"\n",
    "########### train with TrainTestSplit  ###################\n",
    "thread_cnt = 4\n",
    "results = dataset_size_experiment([20, 200, 400, 800, 1600, 3200, 6400, 12800, 16000, 25600] ,path_csv=PATH+\"my_TTS_KNN_app.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example to use the profile mode of our KNNRegressor\n",
    "profiles = []\n",
    "#chsizes = [1, 2, 4, 8, 10, 16, 32]\n",
    "chsizes = [1, 4, 64, 512]\n",
    "for chsize in chsizes:\n",
    "    knn_test = KNNRegressor(p=1, chunk_size=chsize, profile=True)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "\n",
    "    knn_test.fit(x_train, y_train)\n",
    "\n",
    "    total = time()\n",
    "    knn_test.predict(x_test)\n",
    "    total = time() - total\n",
    "    print(total)\n",
    "\n",
    "    profile = knn_test.profile\n",
    "    processed = {\"chunk_size\": chsize, \"total\": total}\n",
    "\n",
    "    for key in profile:\n",
    "        if key in [\"partition\",  \"distances\"]:\n",
    "            val = sum(profile[key])\n",
    "            processed[key] = val\n",
    "        else:\n",
    "            processed[key] = profile[key][0]\n",
    "    profiles.append(processed)\n",
    "\n",
    "print(\"-\"*30)\n",
    "\n",
    "for prof in profiles:\n",
    "    for key in prof:\n",
    "        print(f'{key}: {prof[key]:.4f}')\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## RF-Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = RandomForestRegressor\n",
    "params = {\"n_estimators\" : [10, 100]}\n",
    "NAME = \"RF\"\n",
    "PATH = \"out/\"+NAME+\"/\"\n",
    "\n",
    "modeltrainer = ModelTrainer(MODEL, params, X, Y, thread_cnt=4)\n",
    "########### train with TrainTestSplit  ###################\n",
    "modeltrainer.TTSplit(test_size = test_size)\n",
    "modeltrainer.train()\n",
    "results = modeltrainer.retResults(PATH + \"sklearn_TTS_RF.csv\")\n",
    "display(results)\n",
    "############ shuffle_Cross validation  ###################\n",
    "modeltrainer.CV_shuffle_split(k = n_splits, test_size = test_size, random_state = 42)\n",
    "results = modeltrainer.retResults(PATH + \"sklearn_CV_RF.csv\")\n",
    "display(results)"
   ]
  },
  {
   "source": [
    "## DT-Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = DecisionTreeRegressor\n",
    "params = {\"criterion\": [\"mse\"],\n",
    "          \"max_features\": [\"auto\", \"sqrt\",\"log2\"]}\n",
    "NAME = \"DT\"\n",
    "PATH = \"out/\"+NAME+\"/\"\n",
    "\n",
    "\n",
    "modeltrainer = ModelTrainer(MODEL, params, X, Y, thread_cnt=1)\n",
    "########### train with TrainTestSplit  ###################\n",
    "modeltrainer.TTSplit(test_size = test_size)\n",
    "modeltrainer.train()\n",
    "results = modeltrainer.retResults(PATH + \"sklearn_TTS_DT.csv\")\n",
    "display(results)\n",
    "############ shuffle_Cross validation  ###################\n",
    "modeltrainer.CV_shuffle_split(k = n_splits, test_size = test_size, random_state = 42)\n",
    "results = modeltrainer.retResults(PATH + \"sklearn_CV_DT.csv\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}