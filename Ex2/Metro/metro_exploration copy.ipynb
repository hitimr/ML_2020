{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('ML_2020': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "d6f8d2b41179c5e5fc034bbc40427a4395636c4d26988e51920bd3cc303b8725"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from math import log2\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,PowerTransformer,MinMaxScaler,QuantileTransformer,normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "import pathlib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# for selection the right path\n",
    "import os,sys,inspect,pathlib\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "from common.model_trainer_reg import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functions\n",
    "\n",
    "module_path = pathlib.Path(os.getcwd()).parent\n",
    "if str(module_path) not in sys.path:\n",
    "    sys.path.append(str(module_path))\n",
    "print(sys.path)\n",
    "\n",
    "from common.dataset_grabber import get_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = get_data_path(\"Metro\", \"Metro_Interstate_Traffic_Volume.csv\")\n",
    "display(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(datapath)\n",
    "\n",
    "df_raw"
   ]
  },
  {
   "source": [
    "# Dataset preparation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "source": [
    "# different holiday"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_list = df_raw.holiday.unique()\n",
    "holiday_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in holiday_list:\n",
    "    if l == \"None\":\n",
    "        df_raw = df_raw.replace(l,0)\n",
    "for l in holiday_list:\n",
    "    if l != \"None\":\n",
    "        df_raw = df_raw.replace(l,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_list = df_raw.holiday.unique()\n",
    "holiday_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexNames = df_raw.index[df_raw.holiday == 1]\n",
    "df_raw.drop(indexNames , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "source": [
    "# handling the outlayers\n",
    "## some distributions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The minimal temperature in one row is 0.0 Kelvin that is not possible. So the row will delitet and so the one row with the 9831.3 rain."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_raw[\"temp\"], color=\"red\")\n",
    "plt.show()\n",
    "sns.distplot(df_raw[\"rain_1h\"], color=\"red\")\n",
    "plt.show()\n",
    "sns.distplot(df_raw[\"snow_1h\"], color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## show the outliers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"min Ttemperatur K: \",np.min(df_raw[\"temp\"]),\"mean Ttemperatur K: \",np.mean(df_raw[\"temp\"]))\n",
    "print(\"max rain: \",np.max(df_raw[\"rain_1h\"]),\"mean rain: \",np.mean(df_raw[\"rain_1h\"]))\n",
    "print(\"max snow: \",np.max(df_raw[\"snow_1h\"]),\"max snow: \",np.min(df_raw[\"snow_1h\"]))"
   ]
  },
  {
   "source": [
    "## clean the dataset by dropping the rows with the outlires"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexNames = df_raw.index[df_raw.temp == np.min(df_raw[\"temp\"])]\n",
    "df_raw.drop(indexNames , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"min Ttemperatur K: \",np.min(df_raw[\"temp\"]),\"mean Ttemperatur K: \",np.mean(df_raw[\"temp\"]))\n",
    "print(\"max rain: \",np.max(df_raw[\"rain_1h\"]),\"mean rain: \",np.mean(df_raw[\"rain_1h\"]))\n",
    "print(\"max snow: \",np.max(df_raw[\"snow_1h\"]),\"max snow: \",np.min(df_raw[\"snow_1h\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexNames = df_raw.index[df_raw.rain_1h > 300]\n",
    "df_raw.drop(indexNames , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"min Ttemperatur K: \",np.min(df_raw[\"temp\"]),\"mean Ttemperatur K: \",np.mean(df_raw[\"temp\"]))\n",
    "print(\"max rain: \",np.max(df_raw[\"rain_1h\"]),\"mean rain: \",np.mean(df_raw[\"rain_1h\"]))\n",
    "print(\"max snow: \",np.max(df_raw[\"snow_1h\"]),\"max snow: \",np.min(df_raw[\"snow_1h\"]))"
   ]
  },
  {
   "source": [
    "## looks much better"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_raw[\"temp\"], color=\"red\")\n",
    "plt.show()\n",
    "sns.distplot(df_raw[\"rain_1h\"], color=\"red\")\n",
    "plt.show()\n",
    "sns.distplot(df_raw[\"snow_1h\"], color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## converts the date coloum into a better fromat"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"date_time\"] = pd.to_datetime(df_raw.date_time)\n",
    "df_raw[\"hour\"] = df_raw.date_time.dt.hour\n",
    "df_raw[\"day\"] = df_raw.date_time.dt.day\n",
    "df_raw[\"month\"] = df_raw.date_time.dt.month\n",
    "df_raw[\"year\"] = df_raw.date_time.dt.year\n",
    "\n",
    "df_raw = df_raw.drop(\"date_time\", axis=1)\n",
    "\n",
    "df_raw"
   ]
  },
  {
   "source": [
    "## code the weather discription into numbers\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsitweather = df_raw.weather_main.unique()\n",
    "l = 0\n",
    "for j in lsitweather:\n",
    "    df_raw = df_raw.replace(j,l)\n",
    "    l = l + 1\n",
    "\n",
    "lsitweather = df_raw.weather_description.unique()\n",
    "l = 0\n",
    "for j in lsitweather:\n",
    "    df_raw = df_raw.replace(j,l)\n",
    "    l = l + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "source": [
    "# Prepare it for the training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_to_drop = ['holiday', 'weather_main', 'weather_description']\n",
    "#cols_to_drop = ['holiday', 'weather_main', 'weather_description']\n",
    "#df_prep = df_raw.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df_prep[\"traffic_volume\"])\n",
    "plot = sns.distplot(df_prep[\"traffic_volume\"], color=\"red\")"
   ]
  },
  {
   "source": [
    "# Train and Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## SGD-Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_prep[['traffic_volume']]\n",
    "X = df_prep[[\"temp\",\"rain_1h\",\"snow_1h\",\"clouds_all\",\"hour\",\"day\",\"month\",\"year\",\"weather_main\",\"weather_description\"]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = SGDRegressor\n",
    "params = {\"alpha\" : [0.0001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer = ModelTrainer(MODEL, params, X, Y, r2_score, StandardScaler, train_test_split, KFold, thread_cnt=4)\n",
    "########### train with TrainTestSplit  ###################\n",
    "modeltrainer.TTSplit(perc = 0.7)\n",
    "modeltrainer.train()\n",
    "\n",
    "\n",
    "########### k-Fold Cross validation  ###################\n",
    "modeltrainer.CV_fold(k = 6)\n",
    "modeltrainer.train()"
   ]
  },
  {
   "source": [
    "## KNN-Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KNN.KNNRegressor import KNNRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = KNNRegressor\n",
    "params = {\"weights\" : [\"uniform\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer = ModelTrainer(MODEL, params, X, Y, r2_score, StandardScaler, train_test_split, KFold, thread_cnt=4)\n",
    "########### train with TrainTestSplit  ###################\n",
    "modeltrainer.TTSplit(perc = 0.2)\n",
    "modeltrainer.train()\n",
    "\n",
    "\n",
    "########### k-Fold Cross validation  ###################\n",
    "#modeltrainer.CV_fold(k = 6)\n",
    "#modeltrainer.train()"
   ]
  },
  {
   "source": [
    "## RF-Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = RandomForestRegressor\n",
    "params = {\"n_estimators\" : [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer = ModelTrainer(MODEL, params, X, Y, r2_score, StandardScaler, train_test_split, KFold, thread_cnt=4)\n",
    "########### train with TrainTestSplit  ###################\n",
    "modeltrainer.TTSplit(perc = 0.7)\n",
    "modeltrainer.train()\n",
    "\n",
    "\n",
    "########### k-Fold Cross validation  ###################\n",
    "modeltrainer.CV_fold(k = 6)\n",
    "modeltrainer.train()"
   ]
  },
  {
   "source": [
    "## DT-Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = DecisionTreeRegressor\n",
    "params = {\"criterion\": [\"mse\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltrainer = ModelTrainer(MODEL, params, X, Y, r2_score, StandardScaler, train_test_split, KFold, thread_cnt=4)\n",
    "########### train with TrainTestSplit  ###################\n",
    "modeltrainer.TTSplit(perc = 0.7)\n",
    "modeltrainer.train()\n",
    "\n",
    "\n",
    "########### k-Fold Cross validation  ###################\n",
    "modeltrainer.CV_fold(k = 6)\n",
    "modeltrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}