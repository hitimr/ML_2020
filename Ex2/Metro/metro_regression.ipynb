{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('ML_2020': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "d6f8d2b41179c5e5fc034bbc40427a4395636c4d26988e51920bd3cc303b8725"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import time\n",
    "import pathlib\n",
    "from math import sqrt\n",
    "from math import log2\n",
    "# packgaes\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# packages\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "## sklearn\n",
    "from sklearn.preprocessing import StandardScaler,PowerTransformer,MinMaxScaler,QuantileTransformer,normalize\n",
    "from sklearn.model_selection import train_test_split, learning_curve, ShuffleSplit\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_poisson_deviance\n",
    "from sklearn.metrics import mean_gamma_deviance\n",
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# for selection the right path\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "from common.DataParser import parse_metro\n",
    "from common.model_trainer_reg import *\n",
    "from common.regression_plotfunctions import *\n",
    "\n",
    "\n",
    "from GD.LinearRegression import LinearRegression\n",
    "from KNN.KNNRegressor import KNNRegressor\n",
    "\n",
    "import metro_preprocessing\n"
   ]
  },
  {
   "source": [
    "# Train and Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = parse_metro()\n",
    "df_raw = df_raw.sample(5000)\n",
    "X, Y = metro_preprocessing.preprocessing(df_raw, transform = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_raw\n",
    "# We don't need it anymore :)\n",
    "try:\n",
    "    df_raw\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "test_size = 0.3"
   ]
  },
  {
   "source": [
    "## SGD-Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = SGDRegressor\n",
    "NAME = \"SGD\"\n",
    "PATH = \"out/\"+NAME+\"/\"\n",
    "params = {\"alpha\" : [0.0001,0.00001],\n",
    "          \"max_iter\" : [1000,2000,3000,5000]}\n",
    "\n",
    "\n",
    "modeltrainer = ModelTrainer(MODEL, params, X, Y, thread_cnt=1)\n",
    "########### train with TrainTestSplit  ###################\n",
    "modeltrainer.TTSplit(test_size = test_size)\n",
    "modeltrainer.train()\n",
    "results = modeltrainer.retResults(PATH + \"sklearn_TTS_SGD_raw.csv\")\n",
    "print(PATH + \"sklearn_TTS_SGD.csv\")\n",
    "display(results)\n",
    "############ shuffle_Cross validation  ###################\n",
    "modeltrainer.CV_shuffle_split(k = n_splits, test_size = test_size, random_state = 42)\n",
    "results = modeltrainer.retResults(PATH + \"sklearn_CV_SGD_raw.csv\")\n",
    "display(results)"
   ]
  },
  {
   "source": [
    "## My SGD-Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = LinearRegression\n",
    "params = {\"alpha\" : [0.0001,0.00001],\n",
    "          \"max_iter\" : [1000,2000,3000,5000]}\n",
    "\n",
    "\n",
    "modeltrainer = ModelTrainer(MODEL, params, X, Y, thread_cnt=1)\n",
    "########### train with TrainTestSplit  ###################\n",
    "modeltrainer.TTSplit(test_size = test_size)\n",
    "modeltrainer.train()\n",
    "results = modeltrainer.retResults(PATH + \"my_TTS_SGD_transforamtion.csv\")\n",
    "display(results)\n",
    "############ shuffle_Cross validation  ###################\n",
    "modeltrainer.CV_shuffle_split(k = n_splits, test_size = test_size, random_state = 42)\n",
    "results = modeltrainer.retResults(PATH + \"my_CV_SGD_transforamtion.csv\")\n",
    "display(results)"
   ]
  },
  {
   "source": [
    "## KNN-Regression\n",
    "\n",
    "### Data for runtime analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"KNN\"\n",
    "PATH = \"out/\"+NAME+\"/\"\n",
    "\n",
    "def dataset_size_experiment(\n",
    "        subset_size=np.arange(0.1, 1.1, 0.1),\n",
    "        path_csv=PATH+\"sklearn_TTS_KNN_app.csv\"\n",
    "        ):\n",
    "    results = []\n",
    "    k = 1\n",
    "    break_next = False\n",
    "    for subs in subset_size:\n",
    "        if subs < 1:\n",
    "            n_train = int(subs * len(Y))\n",
    "            print(f\"{100*subs:.2f}% --> n_train={n_train}\")\n",
    "        else:\n",
    "            n_train = subs\n",
    "            print(f\"{100*subs/len(Y):.2f}% --> n_train={n_train}\")\n",
    "        if break_next:\n",
    "            break\n",
    "        if n_train > len(Y):\n",
    "            n_train = len(Y)\n",
    "            break_next = True\n",
    "        modeltrainer = ModelTrainer(MODEL, params, X[:n_train,:], Y[:n_train], thread_cnt=thread_cnt)\n",
    "        modeltrainer.TTSplit(test_size = test_size)\n",
    "        modeltrainer.k = k \n",
    "        modeltrainer.train()\n",
    "        #print(modeltrainer.results)\n",
    "        results.append(modeltrainer.results)\n",
    "        k += 1\n",
    "        print(\"-\"*30)\n",
    "    results = pd.concat(results, ignore_index=True)\n",
    "    results.to_csv(path_csv, index=False)\n",
    "    display(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [20, 200, 400, 800, 1600, 3200, 6400, 12800, 25600, 51200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = KNeighborsRegressor\n",
    "params = {\n",
    "    \"weights\" : [\"uniform\"],\n",
    "    \"algorithm\": [\"brute\", \"kd_tree\", \"ball_tree\"]\n",
    "}\n",
    "NAME = \"KNN\"\n",
    "PATH = \"out/runtimes/\"\n",
    "########### train with TrainTestSplit  ###################\n",
    "thread_cnt = 4\n",
    "results = dataset_size_experiment(subsets ,path_csv=PATH+\"sklearn_TTS_KNN_app.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = KNNRegressor\n",
    "params = {\"n_neighbors\" : [5],\n",
    "           \"p\": [2],\n",
    "           \"chunk_size\": [1, 4]}\n",
    "NAME = \"KNN\"\n",
    "PATH = \"out/runtimes/\"\n",
    "########### train with TrainTestSplit  ###################\n",
    "thread_cnt = 4\n",
    "results = dataset_size_experiment(subsets ,path_csv=PATH+\"my_TTS_KNN_app.csv\")"
   ]
  },
  {
   "source": [
    "#### Rest\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = KNeighborsRegressor\n",
    "params = {\"weights\" : [\"uniform\"],\n",
    "            \"n_neighbors\" : [5,10],\n",
    "           \"p\": [1,2,3]}\n",
    "NAME = \"KNN\"\n",
    "PATH = \"out/\"+NAME+\"/\"\n",
    "\n",
    "\n",
    "modeltrainer = ModelTrainer(MODEL, params, X, Y, thread_cnt=1)\n",
    "########### train with TrainTestSplit  ###################\n",
    "modeltrainer.TTSplit(test_size = test_size)\n",
    "modeltrainer.train()\n",
    "results = modeltrainer.retResults(PATH + \"sklearn_TTS_KNN_raw.csv\")\n",
    "display(results)\n",
    "############ shuffle_Cross validation  ###################\n",
    "modeltrainer.CV_shuffle_split(k = n_splits, test_size = test_size, random_state = 42)\n",
    "results = modeltrainer.retResults(PATH + \"sklearn_CV_KNN_raw.csv\")\n",
    "display(results)"
   ]
  },
  {
   "source": [
    "## my KNN-Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = KNNRegressor\n",
    "params = {\"weights\" : [\"uniform\"],\n",
    "            \"n_neighbors\" : [5,10],\n",
    "           \"p\": [1,2,3],\n",
    "           \"chunk_size\": [1, 4]}\n",
    "NAME = \"KNN\"\n",
    "PATH = \"out/\"+NAME+\"/\"\n",
    "\n",
    "\n",
    "modeltrainer = ModelTrainer(MODEL, params, X, Y, thread_cnt=4)\n",
    "########### train with TrainTestSplit  ###################\n",
    "modeltrainer.TTSplit(test_size = test_size)\n",
    "modeltrainer.train()\n",
    "results = modeltrainer.retResults(PATH + \"my_TTS_KNN_raw.csv\")\n",
    "display(results)\n",
    "############ shuffle_Cross validation  ###################\n",
    "modeltrainer.CV_shuffle_split(k = n_splits, test_size = test_size, random_state = 42)\n",
    "results = modeltrainer.retResults(PATH + \"my_CV_KNN_raw.csv\")\n",
    "display(results)"
   ]
  },
  {
   "source": [
    "## RF-Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = RandomForestRegressor\n",
    "params = {\"n_estimators\" : [100,200],\n",
    "            \"max_features\": [\"auto\", \"sqrt\",\"log2\"]}\n",
    "NAME = \"RF\"\n",
    "PATH = \"out/\"+NAME+\"/\"\n",
    "\n",
    "\n",
    "\n",
    "modeltrainer = ModelTrainer(MODEL, params, X, Y, thread_cnt=1)\n",
    "########### train with TrainTestSplit  ###################\n",
    "modeltrainer.TTSplit(test_size = test_size)\n",
    "modeltrainer.train()\n",
    "results = modeltrainer.retResults(PATH + \"sklearn_TTS_RF_transforamtion.csv\")\n",
    "display(results)\n",
    "############ shuffle_Cross validation  ###################\n",
    "modeltrainer.CV_shuffle_split(k = n_splits, test_size = test_size, random_state = 42)\n",
    "results = modeltrainer.retResults(PATH + \"sklearn_CV_RF_transforamtion.csv\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## DT-Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = DecisionTreeRegressor\n",
    "params = {\"criterion\": [\"mse\"],\n",
    "          \"max_features\": [\"auto\", \"sqrt\",\"log2\"]}\n",
    "NAME = \"DT\"\n",
    "PATH = \"out/\"+NAME+\"/\"\n",
    "n_splits = 10\n",
    "\n",
    "\n",
    "modeltrainer = ModelTrainer(MODEL, params, X, Y, thread_cnt=1)\n",
    "########### train with TrainTestSplit  ###################\n",
    "modeltrainer.TTSplit(test_size = test_size)\n",
    "modeltrainer.train()\n",
    "results = modeltrainer.retResults(PATH + \"sklearn_TTS_DT_raw.csv\")\n",
    "display(results)\n",
    "############ shuffle_Cross validation  ###################\n",
    "modeltrainer.CV_shuffle_split(k = n_splits, test_size = test_size, random_state = 42)\n",
    "results = modeltrainer.retResults(PATH + \"sklearn_CV_DT_raw.csv\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}